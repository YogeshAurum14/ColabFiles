{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb+srv://omkar_eazr:242424@eazr.jzaia.mongodb.net/eazr_test?retryWrites=true&w=majority\")\n",
    "db = client.eazr_test\n",
    "table = db.testdevicedetails\n",
    "userdata = table.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "sms_list = []\n",
    "for user in userdata:\n",
    "    sms_list.append(user['sms'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-e288c1338dda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnew_sms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msms_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_sms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "new_sms = sms_list[12]\n",
    "len(new_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_entity(doc):\n",
    "    if doc.ents:\n",
    "        for token in doc.ents:\n",
    "            print(token.text+' - '+token.label_+' - '+str(spacy.explain(token.label_)))\n",
    "    else:\n",
    "        print('No entity found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Dear Nitin, Last 3 days left! Don't miss out on exciting offers at The WESTSIDE SALE. Enjoy buy 2 get 1 free & additional 5% off on Axis cards. Visit today!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nitin - PERSON - People, including fictional\n",
      "Last 3 days - DATE - Absolute or relative dates or periods\n",
      "The WESTSIDE SALE - ORG - Companies, agencies, institutions, etc.\n",
      "2 - CARDINAL - Numerals that do not fall under another type\n",
      "1 free - CARDINAL - Numerals that do not fall under another type\n",
      "5% - PERCENT - Percentage, including \"%\"\n",
      "today - DATE - Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "show_entity(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u\"Congrats Nitin, hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congrats Nitin - PERSON - People, including fictional\n"
     ]
    }
   ],
   "source": [
    "show_entity(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'Can i have Rs 500 ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 - CARDINAL - Numerals that do not fall under another type\n"
     ]
    }
   ],
   "source": [
    "show_entity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose we wish to add an entity to our own set of entity. comes handy in our organisational purposes\n",
    "doc3 = nlp(u'Liverpool football club aka LFC is located in city of Liverpool in U.K. Famour anthem You\\' ll never walk alone is \\\n",
    "for them. Owner of the club are FSG or Fenway sports group.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Liverpool football club aka LFC is located in city of Liverpool in U.K. Famour anthem You' ll never walk alone is for them. Owner of the club are FSG or Fenway sports group."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFC - ORG - Companies, agencies, institutions, etc.\n",
      "Liverpool - GPE - Countries, cities, states\n",
      "U.K. - GPE - Countries, cities, states\n",
      "Fenway - FAC - Buildings, airports, highways, bridges, etc.\n"
     ]
    }
   ],
   "source": [
    "show_entity(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to add FSG as an organization in our list of entities. we do as follows to achieve this\n",
    "from spacy.tokens import Span\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG = doc3.vocab.strings[u\"ORG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for token in doc3:\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liverpool and 0\n",
      "football and 1\n",
      "club and 2\n",
      "aka and 3\n",
      "LFC and 4\n",
      "is and 5\n",
      "located and 6\n",
      "in and 7\n",
      "city and 8\n",
      "of and 9\n",
      "Liverpool and 10\n",
      "in and 11\n",
      "U.K. and 12\n",
      "Famour and 13\n",
      "anthem and 14\n",
      "You and 15\n",
      "' and 16\n",
      "ll and 17\n",
      "never and 18\n",
      "walk and 19\n",
      "alone and 20\n",
      "is and 21\n",
      "for and 22\n",
      "them and 23\n",
      ". and 24\n",
      "Owner and 25\n",
      "of and 26\n",
      "the and 27\n",
      "club and 28\n",
      "are and 29\n",
      "FSG and 30\n",
      "or and 31\n",
      "Fenway and 32\n",
      "sports and 33\n",
      "group and 34\n",
      ". and 35\n"
     ]
    }
   ],
   "source": [
    "for i in range(36):\n",
    "    print(f\"{doc3[i]} and {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = nlp(u\"Rs. 700.00 credited to a/c XXXXXX9733 on 22-05-21 by a/c linked to VPA dimplejshah761@okicici (UPI Ref No  114213028076).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credited to a/c\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(statement)):\n",
    "#     print(f\"{statement[i]} and {i}\")\n",
    " \n",
    "print(f\"{statement[3:8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_entities = [\"Credited to\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-eb59ae2ab335>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstatement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabel_entities\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mshow_entity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.ents.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.get_entity_info\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    }
   ],
   "source": [
    "statement.ents = list(statement.ents)+ [label_entities]\n",
    "show_entity(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSG and <class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "new_entity = Span(doc3,30,31,label=ORG)\n",
    "print(f\"{new_entity} and {type(new_entity)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3.ents = list(doc3.ents) + [new_entity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFC - ORG - Companies, agencies, institutions, etc.\n",
      "Liverpool - GPE - Countries, cities, states\n",
      "U.K. - GPE - Countries, cities, states\n",
      "FSG - ORG - Companies, agencies, institutions, etc.\n",
      "Fenway - FAC - Buildings, airports, highways, bridges, etc.\n"
     ]
    }
   ],
   "source": [
    "show_entity(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding named entity to all matching spans\n",
    "# if a text has n number of occurence of a word. so tagging them is done as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'The Product-6 is dispatched as product-6 from godown number 6. Product-6 contains the kids clothing of brand  \\\n",
    "Westside. where as the product-6 belongs to go-down number 7 which is mens clothing item of brand SPYKAR.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Product-6, product-6, godown, 6, Product-6, product-6, go-down, 7, SPYKAR)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 - CARDINAL - Numerals that do not fall under another type\n",
      "7 - CARDINAL - Numerals that do not fall under another type\n",
      "SPYKAR - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "show_entity(doc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list=['Product-6','product-6','godown','go-down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_patterns = []\n",
    "for text in phrase_list:\n",
    "    phrase_patterns.append(nlp(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(phrase_patterns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Product-6, product-6, godown, go-down]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    " phrase_patterns=[nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(phrase_patterns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Product-6, product-6, godown, go-down]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('newphrase',None,*phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16006644766151946141, 1, 2),\n",
       " (16006644766151946141, 5, 6),\n",
       " (16006644766151946141, 7, 8),\n",
       " (16006644766151946141, 11, 12),\n",
       " (16006644766151946141, 24, 25),\n",
       " (16006644766151946141, 27, 30)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 Product-6 newphrase\n",
      "5 6 product-6 newphrase\n",
      "7 8 godown newphrase\n",
      "11 12 Product-6 newphrase\n",
      "24 25 product-6 newphrase\n",
      "27 30 go-down newphrase\n"
     ]
    }
   ],
   "source": [
    "for m_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[m_id]\n",
    "    span = doc4[start:end]\n",
    "    print(start, end, span.text, string_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROD = doc4.vocab.strings[u'PRODUCT']\n",
    "PROD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1\n",
      "end 2\n",
      "start 5\n",
      "end 6\n",
      "start 7\n",
      "end 8\n",
      "start 11\n",
      "end 12\n",
      "start 24\n",
      "end 25\n",
      "start 27\n",
      "end 30\n"
     ]
    }
   ],
   "source": [
    "for match in found_matches:\n",
    "    print('start',match[1])\n",
    "    print('end',match[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ents = [Span(doc4,match[1],match[2],label=PROD) for match in found_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4.ents = list(doc4.ents) + new_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product-6 - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "product-6 - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "godown - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "6 - CARDINAL - Numerals that do not fall under another type\n",
      "Product-6 - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "product-6 - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "go-down - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "7 - CARDINAL - Numerals that do not fall under another type\n",
      "SPYKAR - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "show_entity(doc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EXAMPLE 2 #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5 = nlp(u'Bugatti chiron is the fastest car on Earth with speed of 416 kilometers per hour. It has 2500cc and 500bhp. Second fastest \\\n",
    "is the Bugatti veyron with speed of 400 kilometers per hour with 400bhp. Bugatti is a French automobile company formed in 1980. Lamborghini \\\n",
    "is the rival company to the company. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Bugatti chiron,\n",
       " Earth,\n",
       " 416 kilometers per hour,\n",
       " Second,\n",
       " Bugatti,\n",
       " 400 kilometers per hour,\n",
       " Bugatti,\n",
       " French,\n",
       " 1980,\n",
       " Lamborghini)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bugatti chiron - ORG - Companies, agencies, institutions, etc.\n",
      "Earth - LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "416 kilometers per hour - QUANTITY - Measurements, as of weight or distance\n",
      "Second - ORDINAL - \"first\", \"second\", etc.\n",
      "Bugatti - ORG - Companies, agencies, institutions, etc.\n",
      "400 kilometers per hour - QUANTITY - Measurements, as of weight or distance\n",
      "Bugatti - ORG - Companies, agencies, institutions, etc.\n",
      "French - NORP - Nationalities or religious or political groups\n",
      "1980 - DATE - Absolute or relative dates or periods\n",
      "Lamborghini - PERSON - People, including fictional\n"
     ]
    }
   ],
   "source": [
    "show_entity(doc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[500bhp, 400bhp]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "phrs_lst = ['500bhp','400bhp']\n",
    "phrs_ptrns = [nlp(text) for text in phrs_lst]\n",
    "phrs_ptrns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5152663961194670011, 20, 21), (5152663961194670011, 36, 37)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher.add('newphrs',None,*phrs_ptrns)\n",
    "found_match = matcher(doc5)\n",
    "found_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500bhp 20 21\n",
      "400bhp 36 37\n"
     ]
    }
   ],
   "source": [
    "for m_id, start, end in found_match:\n",
    "    span = doc5[start:end]\n",
    "    print(span,start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEA = doc4.vocab.strings[u\"QUANTITY\"]\n",
    "MEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_ent = [Span(doc5,match[1],match[2],label=MEA) for match in found_match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK_OF_ART')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of entity labels in spacy\n",
    "nlp.entity.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5.ents = list(doc5.ents) + fresh_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bugatti chiron - ORG - Companies, agencies, institutions, etc.\n",
      "Earth - LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "416 kilometers per hour - QUANTITY - Measurements, as of weight or distance\n",
      "500bhp - QUANTITY - Measurements, as of weight or distance\n",
      "Second - ORDINAL - \"first\", \"second\", etc.\n",
      "Bugatti - ORG - Companies, agencies, institutions, etc.\n",
      "400 kilometers per hour - QUANTITY - Measurements, as of weight or distance\n",
      "400bhp - QUANTITY - Measurements, as of weight or distance\n",
      "Bugatti - ORG - Companies, agencies, institutions, etc.\n",
      "French - NORP - Nationalities or religious or political groups\n",
      "1980 - DATE - Absolute or relative dates or periods\n",
      "Lamborghini - PERSON - People, including fictional\n"
     ]
    }
   ],
   "source": [
    "show_entity(doc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[416 kilometers per hour, 500bhp, 400 kilometers per hour, 400bhp]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ent for ent in doc5.ents if ent.label_ == \"QUANTITY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ent for ent in doc5.ents if ent.label_ == \"QUANTITY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Sentence segmentation ########\n",
    "# setting up our rule to seperate a sentence on the basis of rule set by us rather eg ; than the period or a fullstop.\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u' The first sentence. The second sentence. The third sentence.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The first sentence.\n",
      "The second sentence.\n",
      "The third sentence.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for token in doc.sents:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-207-cd94eceeac02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# here doc.sents is a generator. that is it does not store whole token in it hence we cant index the sentence.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# here doc.sents is a generator. that is it does not store whole token in a memory hence we cant index the sentence. \n",
    "doc.sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#but doc stores whole in its memory hence we can index it\n",
    "doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ The first sentence., The second sentence., The third sentence.]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still if you want to look at the sentences we can do as follows\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(doc.sents)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now if we want to set a new rule, like seperating a sentence on the basis of ; and not on period. \n",
    "# following is by default pipeline steps that is used by spacy. \n",
    "# we add our set of rules here hence we create a function\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'\"Measurement is just a quantity; It gives exact value of despair.\" -Yogesh Tiwari.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Measurement is just a quantity; It gives exact value of despair.\" -Yogesh Tiwari."
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Measurement is just a quantity; It gives exact value of despair.\" -Yogesh Tiwari.'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Measurement is just a quantity; It gives exact value of despair.\"\n",
      "\n",
      "\n",
      "-Yogesh Tiwari.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we want to seperate the sentence on the basis of ;\n",
    "for snt in doc.sents:\n",
    "    print(snt)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in document object, every token inside its doc object retains its index position which can be accessed \n",
    "# using \"token.i\"\n",
    "def doc_obj_demo(doc):\n",
    "    for token in doc:\n",
    "        print(token)\n",
    "        print(token.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "0\n",
      "Measurement\n",
      "1\n",
      "is\n",
      "2\n",
      "just\n",
      "3\n",
      "a\n",
      "4\n",
      "quantity\n",
      "5\n",
      ";\n",
      "6\n",
      "It\n",
      "7\n",
      "gives\n",
      "8\n",
      "exact\n",
      "9\n",
      "value\n",
      "10\n",
      "of\n",
      "11\n",
      "despair\n",
      "12\n",
      ".\n",
      "13\n",
      "\"\n",
      "14\n",
      "-Yogesh\n",
      "15\n",
      "Tiwari\n",
      "16\n",
      ".\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "doc_obj_demo(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Measurement is just a quantity; It gives exact value of despair.\" -Yogesh Tiwari"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# go through evey token upto last but not including the last\n",
    "doc[:-1]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a new segmetnt rule.\n",
    "def set_custom_boundaries(doc):  \n",
    "    for token in doc[:-1]:\n",
    "        #adding a new segmentation rule\n",
    "        if token.text == \";\":\n",
    "            #we traverse through the token and once we find ;, we indicate that from here new sentence starts\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'set_custom_boundaries', 'parser', 'ner']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we add the rule to the pipeline\n",
    "#hence we added our function which is the rule, before parser\n",
    "\n",
    "nlp.add_pipe(set_custom_boundaries, before = 'parser')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'\"Measurement is just a quantity; It gives exact value of despair.\" -Yogesh Tiwari.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Measurement is just a quantity;\n",
      "It gives exact value of despair.\"\n",
      "-Yogesh Tiwari.\n"
     ]
    }
   ],
   "source": [
    "# now the sentences are getting seperated on the basis of ;\n",
    "for sent in doc2.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second method in achieving sentence segmentation is by changing the rules completely\n",
    "# we want to break the sentence only on the basis of a new line ie \\n\n",
    "\n",
    "mystring = u'Hi mom. We\\'re the millers. \\nAbsolutely great.\\n\\n Class apart \\n from the rest.'\n",
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi mom. We're the millers. \\nAbsolutely great.\\n\\n Class apart \\n from the rest.\""
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hi mom. We're the millers. \n",
       "Absolutely great.\n",
       "\n",
       " Class apart \n",
       " from the rest."
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi mom.\n",
      "We're the millers. \n",
      "\n",
      "Absolutely great.\n",
      "\n",
      " \n",
      "Class apart \n",
      " from the rest.\n"
     ]
    }
   ],
   "source": [
    "for token in doc.sents:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import SentenceSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_newline(doc):\n",
    "    start = 0\n",
    "    if_seen_a_newline = False\n",
    "    for token in doc:\n",
    "        #\"if if_seen_a_newline==True:\" or else can also be written as below\n",
    "        if if_seen_a_newline:\n",
    "            #yield is a generator\n",
    "            yield doc[start:token.i]\n",
    "            start = token.i\n",
    "            if_seen_a_newline = False\n",
    "        elif token.text.startswith(\"\\n\"):\n",
    "            if_seen_a_newline = True\n",
    "    yield doc[start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbd = SentenceSegmenter(nlp.vocab, strategy=split_on_newline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(sbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi mom. We're the millers. \n",
      "\n",
      "Absolutely great.\n",
      "\n",
      " \n",
      "Class apart \n",
      " \n",
      "from the rest.\n"
     ]
    }
   ],
   "source": [
    "for snt in doc.sents:\n",
    "    print(snt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the above eg, fullstop is not considered as a sentence segmenter anymore for doc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict()\n",
    "print(\"break\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "list1.append(2)\n",
    "list1[0]\n",
    "pointer = 0 #for times_number\n",
    "current_position = 0 # for adding two at postion len(list1)+1\n",
    "times_number = list1[0]\n",
    "length_list = len(list1) # for infinite loop\n",
    "while length_list >= 0:\n",
    "    print(length_list)\n",
    "    list1.append(1)\n",
    "    length_list = len(list1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePattern(a, b):\n",
    "    pattern_list = []\n",
    "    current_index_char = a\n",
    "    current_index = 0\n",
    "    # while True:\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            print(a, end=\"|\")\n",
    "            pattern_list.append(a)\n",
    "            for i in range(current_index_char):\n",
    "                print(b, end=\"\")\n",
    "                pattern_list.append(b)\n",
    "            print(\"|\", end=\"\")\n",
    "            current_index += 1\n",
    "            current_index_char = pattern_list[current_index]\n",
    "        except KeyboardInterrupt:\n",
    "            exit(0)\n",
    "    print(\"\")\n",
    "makePattern(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)\n",
    "words = []\n",
    "labels = []\n",
    "\n",
    "for token in doc:\n",
    "\twords.append(token.text)\n",
    "\tlabels.append('O') # As most of token will be non-entity (OUT). Replace this later with actual entity a/c the scheme.\n",
    "\n",
    "df = pd.DataFrame({'word': words, 'label': labels})\n",
    "df.to_csv('ner-token-per-line.biluo', index=False) # biluo in extension to indicate the type of encoding, it is ok to keep csv\n",
    "\n",
    "# view rawpreprocess_text_for_labelling.py hosted with ❤ by GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = 'ner-token-per-line.biluo'\n",
    "\n",
    "df = pd.read_csv(dpath, sep=',')\n",
    "words  = df.word.values\n",
    "ents = df.label.values\n",
    "text = ' '.join(words)\n",
    "\n",
    "from spacy.gold import GoldParse\n",
    "\n",
    "doc = nlp.make_doc(text)\n",
    "g = GoldParse(doc, entities=ents)\n",
    "X = [doc]\n",
    "Y = [g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "g = {'entities': [(5, 20, 'PERSON'), (61, 67, 'ORG'), (71, 75, 'DATE'), (173, 181, 'NORP'), \n",
    "\t\t  (271, 276, 'PERSON'), (299, 305, 'ORG'), (306, 323, 'DATED')]}\n",
    "\n",
    "X = [text]\n",
    "Y = [g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = <list of user token> for example space splitted tokens  \n",
    "spaces = [True]*len(words)\n",
    "spaces[-1] = False # so remove space in last\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces) # Custom Doc\n",
    "g = GoldParse(doc, entities=ents)\n",
    "X = [doc]\n",
    "Y = [g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Existing Entities] =  ['B-ORG', 'B-DATE', 'B-PERSON', 'B-GPE', 'B-MONEY', 'B-CARDINAL', 'B-NORP', 'B-PERCENT', 'B-WORK_OF_ART', 'B-LOC', 'B-TIME', 'B-QUANTITY', 'B-FAC', 'B-EVENT', 'B-ORDINAL', 'B-PRODUCT', 'B-LAW', 'B-LANGUAGE', 'I-ORG', 'I-DATE', 'I-PERSON', 'I-GPE', 'I-MONEY', 'I-CARDINAL', 'I-NORP', 'I-PERCENT', 'I-WORK_OF_ART', 'I-LOC', 'I-TIME', 'I-QUANTITY', 'I-FAC', 'I-EVENT', 'I-ORDINAL', 'I-PRODUCT', 'I-LAW', 'I-LANGUAGE', 'L-ORG', 'L-DATE', 'L-PERSON', 'L-GPE', 'L-MONEY', 'L-CARDINAL', 'L-NORP', 'L-PERCENT', 'L-WORK_OF_ART', 'L-LOC', 'L-TIME', 'L-QUANTITY', 'L-FAC', 'L-EVENT', 'L-ORDINAL', 'L-PRODUCT', 'L-LAW', 'L-LANGUAGE', 'U-ORG', 'U-DATE', 'U-PERSON', 'U-GPE', 'U-MONEY', 'U-CARDINAL', 'U-NORP', 'U-PERCENT', 'U-WORK_OF_ART', 'U-LOC', 'U-TIME', 'U-QUANTITY', 'U-FAC', 'U-EVENT', 'U-ORDINAL', 'U-PRODUCT', 'U-LAW', 'U-LANGUAGE', 'O']\n",
      "\n",
      "\n",
      "[New Entities] =  ['B-DATED', 'L-DATED', 'I-DATED', 'U-DATED']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'other_pipes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-67d31e8e346c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;31m# Since we are training a fresh model not a saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_pipes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mother_pipes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# only train ner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m# optimizer = nlp.begin_training()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'other_pipes' is not defined"
     ]
    }
   ],
   "source": [
    "add_ents = ['DATED'] # The new entity\n",
    "# Piplines in core pretrained model are tagger, parser, ner. Create new if blank model is to be trained using `spacy.blank('en')` else get the existing one.\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\") # \"architecture\": \"ensemble\" simple_cnn ensemble, bow # https://spacy.io/api/annotation\n",
    "    nlp.add_pipe(ner)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "prev_ents = ner.move_names # All the existing entities recognised by the model\n",
    "print('[Existing Entities] = ', ner.move_names)\n",
    "for ent in add_ents:\n",
    "    ner.add_label(ent)\n",
    "    \n",
    "new_ents = ner.move_names\n",
    "# print('\\n[All Entities] = ', ner.move_names)\n",
    "print('\\n\\n[New Entities] = ', list(set(new_ents) - set(prev_ents)))\n",
    "## Training\n",
    "model = None # Since we are training a fresh model not a saved model\n",
    "n_iter = 20\n",
    "with nlp.disable_pipes(*other_pipes):  # only train ner\n",
    "    # optimizer = nlp.begin_training()\n",
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp.resume_training()\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        nlp.update(X, Y,  sgd=optimizer, drop=0.0, losses=losses)\n",
    "        # nlp.entity.update(d, g)\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Thrun PERSON\n",
      "Google ORG\n",
      "2007 DATE\n",
      "American NORP\n",
      "Thrun PERSON\n",
      "Recode LOC\n",
      "earlier this week DATE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "    \n",
    "# # Output  \n",
    "# Sebastian Thrun PERSON\n",
    "# Google ORG\n",
    "# 2007 DATE\n",
    "# American NORP\n",
    "# Thrun PERSON\n",
    "# Recode ORG\n",
    "# earlier this week. DATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously. “I can tell you very senior CEOs of major \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " car companies would shake my hand and turn away because I wasn’t worth talking to,” said \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", in an interview with \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Recode\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    earlier this week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\") # if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load('en') # or any other specific model like 'en_core_web_md' more at https://spacy.io/models/en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gor reproducing same results during mutiple run\n",
    "s = 999\n",
    "np.random.seed(s)\n",
    "spacy.util.fix_random_seed(s)\n",
    "\n",
    "# if Training with GPU also\n",
    "# cupy.random.seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "dpath = 'ner-token-per-line.biluo'\n",
    "df = pd.read_csv(dpath, sep=',')\n",
    "words  = df.word.values\n",
    "ents = df.label.values\n",
    "text = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your a/c XX4233 is debited for Rs. 2000.00 on 21-05-2021 16:13 and credited to a/c XX6193 (UPI Ref no 114106255011).Plz call 18002586465 if not done by you.Rs 400.00 debited from a/c **9733 on 13-12-20 to VPA ktb.ru351318a@icici(UPI Ref No 034847215509). Not you? Call on 18002586161 to reportYour a/c XX4233 is debited for Rs. 2000.00 on 20-05-2021 19:20 and credited to a/c XX4006 (UPI Ref no 114077726731).Plz call 18002586465 if not done by you.Your a/c XX4233 is debited for Rs. 170.00 on 20-05-2021 18:29 and credited to a/c XX1905 (UPI Ref no 114042861522).Plz call 18002586465 if not done by youYour SB A/c **06121 is Credited for Rs.3000 on 06-04-2021 23:01:48 by NEFT.Sender:PRIYANKA MANISH RABH.UTR:N096211465509692 Avl Bal Rs:13422.87 -Union Bank of IndiaYour SB A/c **06121 is Credited for Rs.3000 on 06-05-2021 22:31:36 by NEFT.Sender:PRIYANKA MANISH RABH.UTR:N126211496950765 Avl Bal Rs:16022.87 -Union Bank of IndiaRs400.0 debited@SBI UPI frm A/cX6070 on 19May21 RefNo 113920325111. If not done by u, fwd this SMS to 9223008333/Call 1800111109 or 09449112211 to block UPIYour a/c no. XXXXXXXXXXX6121 is debited for Rs. 1836.00 on 06 Apr 2021, 22:45:39  (UPI Ref no 109622413507).Dear Customer, INR 8,400.00 credited to your A/c No XX6070 on 14/05/2021 through NEFT with UTR P134210108525622 by SAI INSPECTION SERVI, INFO: SalaryforthemonthofApril2021-SBIDear SBI Customer, Rs.1000 withdrawn at ICI ATM SPCNF308 from A/cX6070 on 19May21 Transaction Number 113908006317. Available Balance Rs.9575. If not withdrawn by you, forward this SMS to 9223008333 / call 1800111109 or 09449112211 to block your card. Download YONO SBI. Use SBI ATMs.Dear Customer, your Account XX5605 has been credited with INR 70,503.00 on 06-Nov-18. Info: NEFT-AXIC183104139425-THOUGH. The Available Balance is INR 74,017.61.Dear Customer, your Account XX5605 has been debited with INR 34,760.00 on 06-Nov-18. Info: BIL*DTAX*001572198791*DTAX*C. The Available Balance is INR 39,257.61.For dispute,call 04033667777.An amount of 1081 INR has been debited to A/c no XXXXXXX1030691 by Fund Transfer on 09-NOV-18 10:36:30. Now Clear balance is Credit INR 10535.94Dear Customer, your Account XX5605 has been credited with INR 5,521.00 on 20-Nov-18. Info: NEFT-AXIC183247275097-THOUGH. The Available Balance is INR 13,553.71.Rs.10050 is Debited to A/c ...4971 on 01-12-18 16:04:31 (Avlbl Bal Rs.20615.56). Stay updated with your txns. Get Mobile Banking app http://bit.ly/mconnect2An Amount of 10000 INR has been credited to A/c no XXXXXXX1030691 by EFT / ATM Card transaction. on 07-JAN-19 15:16:19. Now Clear balance is Credit INR 12958.94Fund Transfer to XXXXXX7386 - successful. Rs.2,000.00 debited from XXXXXX4971,Transaction ID:900315025737. Dated on 03-01-2019An amount of 1081 INR has been debited to A/c no XXXXXXX1030691 by Fund Transfer on 07-DEC-18 09:03:12. Now Clear balance is Credit INR 9454.94'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     O\n",
       "1     O\n",
       "2     O\n",
       "3     O\n",
       "4     O\n",
       "     ..\n",
       "61    O\n",
       "62    O\n",
       "63    O\n",
       "64    O\n",
       "65    O\n",
       "Name: label, Length: 66, dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\") # \"architecture\": \"ensemble\" simple_cnn ensemble, bow # https://spacy.io/api/annotation\n",
    "    nlp.add_pipe(ner)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Existing Entities] =  ['B-ORG', 'B-DATE', 'B-PERSON', 'B-GPE', 'B-MONEY', 'B-CARDINAL', 'B-NORP', 'B-PERCENT', 'B-WORK_OF_ART', 'B-LOC', 'B-TIME', 'B-QUANTITY', 'B-FAC', 'B-EVENT', 'B-ORDINAL', 'B-PRODUCT', 'B-LAW', 'B-LANGUAGE', 'I-ORG', 'I-DATE', 'I-PERSON', 'I-GPE', 'I-MONEY', 'I-CARDINAL', 'I-NORP', 'I-PERCENT', 'I-WORK_OF_ART', 'I-LOC', 'I-TIME', 'I-QUANTITY', 'I-FAC', 'I-EVENT', 'I-ORDINAL', 'I-PRODUCT', 'I-LAW', 'I-LANGUAGE', 'L-ORG', 'L-DATE', 'L-PERSON', 'L-GPE', 'L-MONEY', 'L-CARDINAL', 'L-NORP', 'L-PERCENT', 'L-WORK_OF_ART', 'L-LOC', 'L-TIME', 'L-QUANTITY', 'L-FAC', 'L-EVENT', 'L-ORDINAL', 'L-PRODUCT', 'L-LAW', 'L-LANGUAGE', 'U-ORG', 'U-DATE', 'U-PERSON', 'U-GPE', 'U-MONEY', 'U-CARDINAL', 'U-NORP', 'U-PERCENT', 'U-WORK_OF_ART', 'U-LOC', 'U-TIME', 'U-QUANTITY', 'U-FAC', 'U-EVENT', 'U-ORDINAL', 'U-PRODUCT', 'U-LAW', 'U-LANGUAGE', 'O', 'B-DATED', 'I-DATED', 'L-DATED', 'U-DATED', 'B-Credit sms', 'I-Credit sms', 'L-Credit sms', 'U-Credit sms', 'B-account number', 'I-account number', 'L-account number', 'U-account number', 'B-Account number', 'I-Account number', 'L-Account number', 'U-Account number', 'B-debit account', 'I-debit account', 'L-debit account', 'U-debit account', 'B-amount', 'I-amount', 'L-amount', 'U-amount']\n"
     ]
    }
   ],
   "source": [
    "prev_ents = ner.move_names\n",
    "print('[Existing Entities] = ', ner.move_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code to add entity\n",
    "add_ents = ['DATED','Credit sms','account number'] # \n",
    "for ent in add_ents:\n",
    "    ner.add_label(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipe if it does not exist\n",
    "# Piplines in pretrained model: tagger, parser, ner create new if blank model is to be trained using `spacy.blank('en')`\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\") # \"architecture\": \"ensemble\" simple_cnn ensemble, bow # https://spacy.io/api/annotation\n",
    "    nlp.add_pipe(ner)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Existing Entities] =  ['B-ORG', 'B-DATE', 'B-PERSON', 'B-GPE', 'B-MONEY', 'B-CARDINAL', 'B-NORP', 'B-PERCENT', 'B-WORK_OF_ART', 'B-LOC', 'B-TIME', 'B-QUANTITY', 'B-FAC', 'B-EVENT', 'B-ORDINAL', 'B-PRODUCT', 'B-LAW', 'B-LANGUAGE', 'I-ORG', 'I-DATE', 'I-PERSON', 'I-GPE', 'I-MONEY', 'I-CARDINAL', 'I-NORP', 'I-PERCENT', 'I-WORK_OF_ART', 'I-LOC', 'I-TIME', 'I-QUANTITY', 'I-FAC', 'I-EVENT', 'I-ORDINAL', 'I-PRODUCT', 'I-LAW', 'I-LANGUAGE', 'L-ORG', 'L-DATE', 'L-PERSON', 'L-GPE', 'L-MONEY', 'L-CARDINAL', 'L-NORP', 'L-PERCENT', 'L-WORK_OF_ART', 'L-LOC', 'L-TIME', 'L-QUANTITY', 'L-FAC', 'L-EVENT', 'L-ORDINAL', 'L-PRODUCT', 'L-LAW', 'L-LANGUAGE', 'U-ORG', 'U-DATE', 'U-PERSON', 'U-GPE', 'U-MONEY', 'U-CARDINAL', 'U-NORP', 'U-PERCENT', 'U-WORK_OF_ART', 'U-LOC', 'U-TIME', 'U-QUANTITY', 'U-FAC', 'U-EVENT', 'U-ORDINAL', 'U-PRODUCT', 'U-LAW', 'U-LANGUAGE', 'O', 'B-DATED', 'I-DATED', 'L-DATED', 'U-DATED', 'B-Credit sms', 'I-Credit sms', 'L-Credit sms', 'U-Credit sms', 'B-account number', 'I-account number', 'L-account number', 'U-account number']\n"
     ]
    }
   ],
   "source": [
    "prev_ents = ner.move_names\n",
    "print('[Existing Entities] = ', ner.move_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in add_ents:\n",
    "    ner.add_label(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[New Entities] =  []\n"
     ]
    }
   ],
   "source": [
    "new_ents = ner.move_names\n",
    "print('\\n\\n[New Entities] = ', list(set(new_ents) - set(prev_ents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Existing Entities] =  ['B-ORG', 'B-DATE', 'B-PERSON', 'B-GPE', 'B-MONEY', 'B-CARDINAL', 'B-NORP', 'B-PERCENT', 'B-WORK_OF_ART', 'B-LOC', 'B-TIME', 'B-QUANTITY', 'B-FAC', 'B-EVENT', 'B-ORDINAL', 'B-PRODUCT', 'B-LAW', 'B-LANGUAGE', 'I-ORG', 'I-DATE', 'I-PERSON', 'I-GPE', 'I-MONEY', 'I-CARDINAL', 'I-NORP', 'I-PERCENT', 'I-WORK_OF_ART', 'I-LOC', 'I-TIME', 'I-QUANTITY', 'I-FAC', 'I-EVENT', 'I-ORDINAL', 'I-PRODUCT', 'I-LAW', 'I-LANGUAGE', 'L-ORG', 'L-DATE', 'L-PERSON', 'L-GPE', 'L-MONEY', 'L-CARDINAL', 'L-NORP', 'L-PERCENT', 'L-WORK_OF_ART', 'L-LOC', 'L-TIME', 'L-QUANTITY', 'L-FAC', 'L-EVENT', 'L-ORDINAL', 'L-PRODUCT', 'L-LAW', 'L-LANGUAGE', 'U-ORG', 'U-DATE', 'U-PERSON', 'U-GPE', 'U-MONEY', 'U-CARDINAL', 'U-NORP', 'U-PERCENT', 'U-WORK_OF_ART', 'U-LOC', 'U-TIME', 'U-QUANTITY', 'U-FAC', 'U-EVENT', 'U-ORDINAL', 'U-PRODUCT', 'U-LAW', 'U-LANGUAGE', 'O', 'B-DATED', 'I-DATED', 'L-DATED', 'U-DATED', 'B-Credit sms', 'I-Credit sms', 'L-Credit sms', 'U-Credit sms', 'B-account number', 'I-account number', 'L-account number', 'U-account number']\n",
      "\n",
      "\n",
      "[New Entities] =  ['B-Account number', 'I-Account number', 'U-debit account', 'U-amount', 'U-Account number', 'L-amount', 'L-Account number', 'B-amount', 'I-amount', 'I-debit account', 'B-debit account', 'L-debit account']\n"
     ]
    }
   ],
   "source": [
    "# Provide all the extra entity that the model should recognise beyond existing named-entities https://spacy.io/api/annotation#named-entities\n",
    "add_ents = [\"Account number\",\"debit account\",\"amount\",\"amount\"] # \n",
    "\n",
    "# Create a pipe if it does not exist\n",
    "# Piplines in pretrained model: tagger, parser, ner create new if blank model is to be trained using `spacy.blank('en')`\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\") # \"architecture\": \"ensemble\" simple_cnn ensemble, bow # https://spacy.io/api/annotation\n",
    "    nlp.add_pipe(ner)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "prev_ents = ner.move_names\n",
    "print('[Existing Entities] = ', ner.move_names)\n",
    "\n",
    "for ent in add_ents:\n",
    "    ner.add_label(ent)\n",
    "    \n",
    "new_ents = ner.move_names\n",
    "# print('\\n[All Entities] = ', ner.move_names)\n",
    "\n",
    "print('\\n\\n[New Entities] = ', list(set(new_ents) - set(prev_ents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sebastian</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thrun</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>started</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>working</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Recode</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>earlier</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>this</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>week</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word label\n",
       "0        When     O\n",
       "1   Sebastian     O\n",
       "2       Thrun     O\n",
       "3     started     O\n",
       "4     working     O\n",
       "..        ...   ...\n",
       "61     Recode     O\n",
       "62    earlier     O\n",
       "63       this     O\n",
       "64       week     O\n",
       "65          .     O\n",
       "\n",
       "[66 rows x 2 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create Dataset\n",
    "from spacy.gold import GoldParse\n",
    "doc = nlp.make_doc(text)\n",
    "g = GoldParse(doc, entities=ents)\n",
    "\n",
    "# Add examples as avaialble or needed\n",
    "X = [doc, doc]\n",
    "Y = [g, g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OtherPipes] = ['tagger', 'parser'] will be disabled\n"
     ]
    }
   ],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "print(f'[OtherPipes] = {other_pipes} will be disabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 25.262126169121128}\n",
      "Losses {'ner': 15.081464783216191}\n",
      "Losses {'ner': 8.2989179553296}\n",
      "Losses {'ner': 4.328741837561667}\n",
      "Losses {'ner': 0.05852929488464523}\n",
      "Losses {'ner': 0.00023860322295833085}\n",
      "Losses {'ner': 1.6286572928612867e-05}\n",
      "Losses {'ner': 1.8518873354487362e-06}\n",
      "Losses {'ner': 4.840905987710466e-07}\n",
      "Losses {'ner': 2.2199852595852893e-07}\n",
      "Losses {'ner': 1.15271639353849e-07}\n",
      "Losses {'ner': 6.175909488258536e-08}\n",
      "Losses {'ner': 3.606953621715752e-08}\n",
      "Losses {'ner': 2.181371562928862e-08}\n",
      "Losses {'ner': 1.3453497986942936e-08}\n",
      "Losses {'ner': 8.608105908874456e-09}\n",
      "Losses {'ner': 5.713255782995499e-09}\n",
      "Losses {'ner': 4.006712513882565e-09}\n",
      "Losses {'ner': 2.969064230994737e-09}\n",
      "Losses {'ner': 2.289825904056103e-09}\n"
     ]
    }
   ],
   "source": [
    "model = None # Since we training a fresh model not a saved model\n",
    "n_iter = 20\n",
    "with nlp.disable_pipes(*other_pipes):  # only train ner\n",
    "    # optimizer = nlp.begin_training()\n",
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp.resume_training()\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        nlp.update(X, Y,  sgd=optimizer, drop=0.0, losses=losses)\n",
    "        # nlp.entity.update(d, g)\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(test_text)\n",
    "# print(\"[Entities] in '%s'\" % test_text, '\\n\\n')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For one instance\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week. \")\n",
    "doc = text\n",
    "g = {'entities': [(5, 20, 'PERSON'), (61, 67, 'ORG'), (71, 75, 'DATE'), (173, 181, 'NORP'), \n",
    "    (271, 276, 'PERSON'), (299, 305, 'ORG'), (306, 323, 'DATED')]}\n",
    "\n",
    "X = [doc]\n",
    "Y = [g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{text[61:67]}\")\n",
    "\n",
    "text = (\"Your a/c XX4233 is debited for Rs. 2000.00 on 21-05-2021 16:13 and credited to a/c XX6193 (UPI Ref no 114106255011).Plz call 18002586465 if not done by you.\"\n",
    "        \"Rs 400.00 debited from a/c **9733 on 13-12-20 to VPA ktb.ru351318a@icici(UPI Ref No 034847215509). Not you? Call on 18002586161 to report\"\n",
    "        \"Your a/c XX4233 is debited for Rs. 2000.00 on 20-05-2021 19:20 and credited to a/c XX4006 (UPI Ref no 114077726731).Plz call 18002586465 if not done by you.\"\n",
    "        \"Your a/c XX4233 is debited for Rs. 170.00 on 20-05-2021 18:29 and credited to a/c XX1905 (UPI Ref no 114042861522).Plz call 18002586465 if not done by you\"\n",
    "        \"Your SB A/c **06121 is Credited for Rs.3000 on 06-04-2021 23:01:48 by NEFT.Sender:PRIYANKA MANISH RABH.UTR:N096211465509692 Avl Bal Rs:13422.87 -Union Bank of India\"\n",
    "        \"Your SB A/c **06121 is Credited for Rs.3000 on 06-05-2021 22:31:36 by NEFT.Sender:PRIYANKA MANISH RABH.UTR:N126211496950765 Avl Bal Rs:16022.87 -Union Bank of India\"\n",
    "        \"Rs400.0 debited@SBI UPI frm A/cX6070 on 19May21 RefNo 113920325111. If not done by u, fwd this SMS to 9223008333/Call 1800111109 or 09449112211 to block UPI\"\n",
    "        \"Your a/c no. XXXXXXXXXXX6121 is debited for Rs. 1836.00 on 06 Apr 2021, 22:45:39  (UPI Ref no 109622413507).\"\n",
    "        \"Dear Customer, INR 8,400.00 credited to your A/c No XX6070 on 14/05/2021 through NEFT with UTR P134210108525622 by SAI INSPECTION SERVI, INFO: SalaryforthemonthofApril2021-SBI\"\n",
    "        \"Dear SBI Customer, Rs.1000 withdrawn at ICI ATM SPCNF308 from A/cX6070 on 19May21 Transaction Number 113908006317. Available Balance Rs.9575. If not withdrawn by you, forward this SMS to 9223008333 / call 1800111109 or 09449112211 to block your card. Download YONO SBI. Use SBI ATMs.\"\n",
    "        \"Dear Customer, your Account XX5605 has been credited with INR 70,503.00 on 06-Nov-18. Info: NEFT-AXIC183104139425-THOUGH. The Available Balance is INR 74,017.61.\"\n",
    "        \"Dear Customer, your Account XX5605 has been debited with INR 34,760.00 on 06-Nov-18. Info: BIL*DTAX*001572198791*DTAX*C. The Available Balance is INR 39,257.61.For dispute,call 04033667777.\"\n",
    "        \"An amount of 1081 INR has been debited to A/c no XXXXXXX1030691 by Fund Transfer on 09-NOV-18 10:36:30. Now Clear balance is Credit INR 10535.94\"\n",
    "        \"Dear Customer, your Account XX5605 has been credited with INR 5,521.00 on 20-Nov-18. Info: NEFT-AXIC183247275097-THOUGH. The Available Balance is INR 13,553.71.\"\n",
    "        \"Rs.10050 is Debited to A/c ...4971 on 01-12-18 16:04:31 (Avlbl Bal Rs.20615.56). Stay updated with your txns. Get Mobile Banking app http://bit.ly/mconnect2\"\n",
    "        \"An Amount of 10000 INR has been credited to A/c no XXXXXXX1030691 by EFT / ATM Card transaction. on 07-JAN-19 15:16:19. Now Clear balance is Credit INR 12958.94\"\n",
    "        \"Fund Transfer to XXXXXX7386 - successful. Rs.2,000.00 debited from XXXXXX4971,Transaction ID:900315025737. Dated on 03-01-2019\"\n",
    "        \"An amount of 1081 INR has been debited to A/c no XXXXXXX1030691 by Fund Transfer on 07-DEC-18 09:03:12. Now Clear balance is Credit INR 9454.94\")\n",
    "\n",
    "doc45 = text\n",
    "g = {\"entities\":[(5,15, \"Account number\"),(19,26,\"debit account\"), (31,42,\"amount\"),\n",
    "                  (156,164,\"amount\"),(166,173,\"debit account\"),(179,189,\"Account number\"),\n",
    "                 (298,308,\"Account number\"),(324,335,\"amount\"),(302,319,\"debit account\"),\n",
    "                  (454,464,'Account number'),(468,475,'debit account'),(480,490,'amount'),\n",
    "                 (611,622,\"Account number\"),(626,634,\"credit account\"),(639,646,\"amount\"),\n",
    "                 (775,786,\"Account number\"),(790,798,\"credit account\"),(803,810,\"amount\"),\n",
    "                 (931,938,\"amount\"),(939,946,\"debit account\"),(959,967,\"Account number\"),\n",
    "                 (1092,1115,\"Account number\"),(1119,1126,\"debit account\"),(1131,1142,\"Debited amount\"),\n",
    "                 (1210,1222,\"amount\"),(1223,1231,\"credit account\"),(1240,1253,\"Account number\"),\n",
    "                 (1389,1396,\"amount\"),(1432,1440,\"Account number\"),(1397,1406,\"debit account\"),\n",
    "                 (1681,1687,\"Account number\"),(1697,1705,\"credit account\"),(1711,1724,\"amount\"),\n",
    "                 (1842,1848,\"Account number\"),(1858,1865,\"debit account\"),(1871,1884,\"amount\"),\n",
    "                 (2016,2024,\"amount\"),(2034,2041,\"debit account\"),(2045,2066,\"Account number\"),\n",
    "                 (2307,2315,\"amount\"),(2319,2326,\"debit account\"),(2330,2341,\"Account number\")]}\n",
    "\n",
    "X = [doc45]\n",
    "Y = g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y and 0\n",
      "o and 1\n",
      "u and 2\n",
      "r and 3\n",
      "  and 4\n",
      "a and 5\n",
      "/ and 6\n",
      "c and 7\n",
      "  and 8\n",
      "X and 9\n",
      "X and 10\n",
      "4 and 11\n",
      "2 and 12\n",
      "3 and 13\n",
      "3 and 14\n",
      "  and 15\n",
      "i and 16\n",
      "s and 17\n",
      "  and 18\n",
      "d and 19\n",
      "e and 20\n",
      "b and 21\n",
      "i and 22\n",
      "t and 23\n",
      "e and 24\n",
      "d and 25\n",
      "  and 26\n",
      "f and 27\n",
      "o and 28\n",
      "r and 29\n",
      "  and 30\n",
      "R and 31\n",
      "s and 32\n",
      ". and 33\n",
      "  and 34\n",
      "2 and 35\n",
      "0 and 36\n",
      "0 and 37\n",
      "0 and 38\n",
      ". and 39\n",
      "0 and 40\n",
      "0 and 41\n",
      "  and 42\n",
      "o and 43\n",
      "n and 44\n",
      "  and 45\n",
      "2 and 46\n",
      "1 and 47\n",
      "- and 48\n",
      "0 and 49\n",
      "5 and 50\n",
      "- and 51\n",
      "2 and 52\n",
      "0 and 53\n",
      "2 and 54\n",
      "1 and 55\n",
      "  and 56\n",
      "1 and 57\n",
      "6 and 58\n",
      ": and 59\n",
      "1 and 60\n",
      "3 and 61\n",
      "  and 62\n",
      "a and 63\n",
      "n and 64\n",
      "d and 65\n",
      "  and 66\n",
      "c and 67\n",
      "r and 68\n",
      "e and 69\n",
      "d and 70\n",
      "i and 71\n",
      "t and 72\n",
      "e and 73\n",
      "d and 74\n",
      "  and 75\n",
      "t and 76\n",
      "o and 77\n",
      "  and 78\n",
      "a and 79\n",
      "/ and 80\n",
      "c and 81\n",
      "  and 82\n",
      "X and 83\n",
      "X and 84\n",
      "6 and 85\n",
      "1 and 86\n",
      "9 and 87\n",
      "3 and 88\n",
      "  and 89\n",
      "( and 90\n",
      "U and 91\n",
      "P and 92\n",
      "I and 93\n",
      "  and 94\n",
      "R and 95\n",
      "e and 96\n",
      "f and 97\n",
      "  and 98\n",
      "n and 99\n",
      "o and 100\n",
      "  and 101\n",
      "1 and 102\n",
      "1 and 103\n",
      "4 and 104\n",
      "1 and 105\n",
      "0 and 106\n",
      "6 and 107\n",
      "2 and 108\n",
      "5 and 109\n",
      "5 and 110\n",
      "0 and 111\n",
      "1 and 112\n",
      "1 and 113\n",
      ") and 114\n",
      ". and 115\n",
      "P and 116\n",
      "l and 117\n",
      "z and 118\n",
      "  and 119\n",
      "c and 120\n",
      "a and 121\n",
      "l and 122\n",
      "l and 123\n",
      "  and 124\n",
      "1 and 125\n",
      "8 and 126\n",
      "0 and 127\n",
      "0 and 128\n",
      "2 and 129\n",
      "5 and 130\n",
      "8 and 131\n",
      "6 and 132\n",
      "4 and 133\n",
      "6 and 134\n",
      "5 and 135\n",
      "  and 136\n",
      "i and 137\n",
      "f and 138\n",
      "  and 139\n",
      "n and 140\n",
      "o and 141\n",
      "t and 142\n",
      "  and 143\n",
      "d and 144\n",
      "o and 145\n",
      "n and 146\n",
      "e and 147\n",
      "  and 148\n",
      "b and 149\n",
      "y and 150\n",
      "  and 151\n",
      "y and 152\n",
      "o and 153\n",
      "u and 154\n",
      ". and 155\n",
      "R and 156\n",
      "s and 157\n",
      "  and 158\n",
      "4 and 159\n",
      "0 and 160\n",
      "0 and 161\n",
      ". and 162\n",
      "0 and 163\n",
      "0 and 164\n",
      "  and 165\n",
      "d and 166\n",
      "e and 167\n",
      "b and 168\n",
      "i and 169\n",
      "t and 170\n",
      "e and 171\n",
      "d and 172\n",
      "  and 173\n",
      "f and 174\n",
      "r and 175\n",
      "o and 176\n",
      "m and 177\n",
      "  and 178\n",
      "a and 179\n",
      "/ and 180\n",
      "c and 181\n",
      "  and 182\n",
      "* and 183\n",
      "* and 184\n",
      "9 and 185\n",
      "7 and 186\n",
      "3 and 187\n",
      "3 and 188\n",
      "  and 189\n",
      "o and 190\n",
      "n and 191\n",
      "  and 192\n",
      "1 and 193\n",
      "3 and 194\n",
      "- and 195\n",
      "1 and 196\n",
      "2 and 197\n",
      "- and 198\n",
      "2 and 199\n",
      "0 and 200\n",
      "  and 201\n",
      "t and 202\n",
      "o and 203\n",
      "  and 204\n",
      "V and 205\n",
      "P and 206\n",
      "A and 207\n",
      "  and 208\n",
      "k and 209\n",
      "t and 210\n",
      "b and 211\n",
      ". and 212\n",
      "r and 213\n",
      "u and 214\n",
      "3 and 215\n",
      "5 and 216\n",
      "1 and 217\n",
      "3 and 218\n",
      "1 and 219\n",
      "8 and 220\n",
      "a and 221\n",
      "@ and 222\n",
      "i and 223\n",
      "c and 224\n",
      "i and 225\n",
      "c and 226\n",
      "i and 227\n",
      "( and 228\n",
      "U and 229\n",
      "P and 230\n",
      "I and 231\n",
      "  and 232\n",
      "R and 233\n",
      "e and 234\n",
      "f and 235\n",
      "  and 236\n",
      "N and 237\n",
      "o and 238\n",
      "  and 239\n",
      "0 and 240\n",
      "3 and 241\n",
      "4 and 242\n",
      "8 and 243\n",
      "4 and 244\n",
      "7 and 245\n",
      "2 and 246\n",
      "1 and 247\n",
      "5 and 248\n",
      "5 and 249\n",
      "0 and 250\n",
      "9 and 251\n",
      ") and 252\n",
      ". and 253\n",
      "  and 254\n",
      "N and 255\n",
      "o and 256\n",
      "t and 257\n",
      "  and 258\n",
      "y and 259\n",
      "o and 260\n",
      "u and 261\n",
      "? and 262\n",
      "  and 263\n",
      "C and 264\n",
      "a and 265\n",
      "l and 266\n",
      "l and 267\n",
      "  and 268\n",
      "o and 269\n",
      "n and 270\n",
      "  and 271\n",
      "1 and 272\n",
      "8 and 273\n",
      "0 and 274\n",
      "0 and 275\n",
      "2 and 276\n",
      "5 and 277\n",
      "8 and 278\n",
      "6 and 279\n",
      "1 and 280\n",
      "6 and 281\n",
      "1 and 282\n",
      "  and 283\n",
      "t and 284\n",
      "o and 285\n",
      "  and 286\n",
      "r and 287\n",
      "e and 288\n",
      "p and 289\n",
      "o and 290\n",
      "r and 291\n",
      "t and 292\n",
      "Y and 293\n",
      "o and 294\n",
      "u and 295\n",
      "r and 296\n",
      "  and 297\n",
      "a and 298\n",
      "/ and 299\n",
      "c and 300\n",
      "  and 301\n",
      "X and 302\n",
      "X and 303\n",
      "4 and 304\n",
      "2 and 305\n",
      "3 and 306\n",
      "3 and 307\n",
      "  and 308\n",
      "i and 309\n",
      "s and 310\n",
      "  and 311\n",
      "d and 312\n",
      "e and 313\n",
      "b and 314\n",
      "i and 315\n",
      "t and 316\n",
      "e and 317\n",
      "d and 318\n",
      "  and 319\n",
      "f and 320\n",
      "o and 321\n",
      "r and 322\n",
      "  and 323\n",
      "R and 324\n",
      "s and 325\n",
      ". and 326\n",
      "  and 327\n",
      "2 and 328\n",
      "0 and 329\n",
      "0 and 330\n",
      "0 and 331\n",
      ". and 332\n",
      "0 and 333\n",
      "0 and 334\n",
      "  and 335\n",
      "o and 336\n",
      "n and 337\n",
      "  and 338\n",
      "2 and 339\n",
      "0 and 340\n",
      "- and 341\n",
      "0 and 342\n",
      "5 and 343\n",
      "- and 344\n",
      "2 and 345\n",
      "0 and 346\n",
      "2 and 347\n",
      "1 and 348\n",
      "  and 349\n",
      "1 and 350\n",
      "9 and 351\n",
      ": and 352\n",
      "2 and 353\n",
      "0 and 354\n",
      "  and 355\n",
      "a and 356\n",
      "n and 357\n",
      "d and 358\n",
      "  and 359\n",
      "c and 360\n",
      "r and 361\n",
      "e and 362\n",
      "d and 363\n",
      "i and 364\n",
      "t and 365\n",
      "e and 366\n",
      "d and 367\n",
      "  and 368\n",
      "t and 369\n",
      "o and 370\n",
      "  and 371\n",
      "a and 372\n",
      "/ and 373\n",
      "c and 374\n",
      "  and 375\n",
      "X and 376\n",
      "X and 377\n",
      "4 and 378\n",
      "0 and 379\n",
      "0 and 380\n",
      "6 and 381\n",
      "  and 382\n",
      "( and 383\n",
      "U and 384\n",
      "P and 385\n",
      "I and 386\n",
      "  and 387\n",
      "R and 388\n",
      "e and 389\n",
      "f and 390\n",
      "  and 391\n",
      "n and 392\n",
      "o and 393\n",
      "  and 394\n",
      "1 and 395\n",
      "1 and 396\n",
      "4 and 397\n",
      "0 and 398\n",
      "7 and 399\n",
      "7 and 400\n",
      "7 and 401\n",
      "2 and 402\n",
      "6 and 403\n",
      "7 and 404\n",
      "3 and 405\n",
      "1 and 406\n",
      ") and 407\n",
      ". and 408\n",
      "P and 409\n",
      "l and 410\n",
      "z and 411\n",
      "  and 412\n",
      "c and 413\n",
      "a and 414\n",
      "l and 415\n",
      "l and 416\n",
      "  and 417\n",
      "1 and 418\n",
      "8 and 419\n",
      "0 and 420\n",
      "0 and 421\n",
      "2 and 422\n",
      "5 and 423\n",
      "8 and 424\n",
      "6 and 425\n",
      "4 and 426\n",
      "6 and 427\n",
      "5 and 428\n",
      "  and 429\n",
      "i and 430\n",
      "f and 431\n",
      "  and 432\n",
      "n and 433\n",
      "o and 434\n",
      "t and 435\n",
      "  and 436\n",
      "d and 437\n",
      "o and 438\n",
      "n and 439\n",
      "e and 440\n",
      "  and 441\n",
      "b and 442\n",
      "y and 443\n",
      "  and 444\n",
      "y and 445\n",
      "o and 446\n",
      "u and 447\n",
      ". and 448\n",
      "Y and 449\n",
      "o and 450\n",
      "u and 451\n",
      "r and 452\n",
      "  and 453\n",
      "a and 454\n",
      "/ and 455\n",
      "c and 456\n",
      "  and 457\n",
      "X and 458\n",
      "X and 459\n",
      "4 and 460\n",
      "2 and 461\n",
      "3 and 462\n",
      "3 and 463\n",
      "  and 464\n",
      "i and 465\n",
      "s and 466\n",
      "  and 467\n",
      "d and 468\n",
      "e and 469\n",
      "b and 470\n",
      "i and 471\n",
      "t and 472\n",
      "e and 473\n",
      "d and 474\n",
      "  and 475\n",
      "f and 476\n",
      "o and 477\n",
      "r and 478\n",
      "  and 479\n",
      "R and 480\n",
      "s and 481\n",
      ". and 482\n",
      "  and 483\n",
      "1 and 484\n",
      "7 and 485\n",
      "0 and 486\n",
      ". and 487\n",
      "0 and 488\n",
      "0 and 489\n",
      "  and 490\n",
      "o and 491\n",
      "n and 492\n",
      "  and 493\n",
      "2 and 494\n",
      "0 and 495\n",
      "- and 496\n",
      "0 and 497\n",
      "5 and 498\n",
      "- and 499\n",
      "2 and 500\n",
      "0 and 501\n",
      "2 and 502\n",
      "1 and 503\n",
      "  and 504\n",
      "1 and 505\n",
      "8 and 506\n",
      ": and 507\n",
      "2 and 508\n",
      "9 and 509\n",
      "  and 510\n",
      "a and 511\n",
      "n and 512\n",
      "d and 513\n",
      "  and 514\n",
      "c and 515\n",
      "r and 516\n",
      "e and 517\n",
      "d and 518\n",
      "i and 519\n",
      "t and 520\n",
      "e and 521\n",
      "d and 522\n",
      "  and 523\n",
      "t and 524\n",
      "o and 525\n",
      "  and 526\n",
      "a and 527\n",
      "/ and 528\n",
      "c and 529\n",
      "  and 530\n",
      "X and 531\n",
      "X and 532\n",
      "1 and 533\n",
      "9 and 534\n",
      "0 and 535\n",
      "5 and 536\n",
      "  and 537\n",
      "( and 538\n",
      "U and 539\n",
      "P and 540\n",
      "I and 541\n",
      "  and 542\n",
      "R and 543\n",
      "e and 544\n",
      "f and 545\n",
      "  and 546\n",
      "n and 547\n",
      "o and 548\n",
      "  and 549\n",
      "1 and 550\n",
      "1 and 551\n",
      "4 and 552\n",
      "0 and 553\n",
      "4 and 554\n",
      "2 and 555\n",
      "8 and 556\n",
      "6 and 557\n",
      "1 and 558\n",
      "5 and 559\n",
      "2 and 560\n",
      "2 and 561\n",
      ") and 562\n",
      ". and 563\n",
      "P and 564\n",
      "l and 565\n",
      "z and 566\n",
      "  and 567\n",
      "c and 568\n",
      "a and 569\n",
      "l and 570\n",
      "l and 571\n",
      "  and 572\n",
      "1 and 573\n",
      "8 and 574\n",
      "0 and 575\n",
      "0 and 576\n",
      "2 and 577\n",
      "5 and 578\n",
      "8 and 579\n",
      "6 and 580\n",
      "4 and 581\n",
      "6 and 582\n",
      "5 and 583\n",
      "  and 584\n",
      "i and 585\n",
      "f and 586\n",
      "  and 587\n",
      "n and 588\n",
      "o and 589\n",
      "t and 590\n",
      "  and 591\n",
      "d and 592\n",
      "o and 593\n",
      "n and 594\n",
      "e and 595\n",
      "  and 596\n",
      "b and 597\n",
      "y and 598\n",
      "  and 599\n",
      "y and 600\n",
      "o and 601\n",
      "u and 602\n",
      "Y and 603\n",
      "o and 604\n",
      "u and 605\n",
      "r and 606\n",
      "  and 607\n",
      "S and 608\n",
      "B and 609\n",
      "  and 610\n",
      "A and 611\n",
      "/ and 612\n",
      "c and 613\n",
      "  and 614\n",
      "* and 615\n",
      "* and 616\n",
      "0 and 617\n",
      "6 and 618\n",
      "1 and 619\n",
      "2 and 620\n",
      "1 and 621\n",
      "  and 622\n",
      "i and 623\n",
      "s and 624\n",
      "  and 625\n",
      "C and 626\n",
      "r and 627\n",
      "e and 628\n",
      "d and 629\n",
      "i and 630\n",
      "t and 631\n",
      "e and 632\n",
      "d and 633\n",
      "  and 634\n",
      "f and 635\n",
      "o and 636\n",
      "r and 637\n",
      "  and 638\n",
      "R and 639\n",
      "s and 640\n",
      ". and 641\n",
      "3 and 642\n",
      "0 and 643\n",
      "0 and 644\n",
      "0 and 645\n",
      "  and 646\n",
      "o and 647\n",
      "n and 648\n",
      "  and 649\n",
      "0 and 650\n",
      "6 and 651\n",
      "- and 652\n",
      "0 and 653\n",
      "4 and 654\n",
      "- and 655\n",
      "2 and 656\n",
      "0 and 657\n",
      "2 and 658\n",
      "1 and 659\n",
      "  and 660\n",
      "2 and 661\n",
      "3 and 662\n",
      ": and 663\n",
      "0 and 664\n",
      "1 and 665\n",
      ": and 666\n",
      "4 and 667\n",
      "8 and 668\n",
      "  and 669\n",
      "b and 670\n",
      "y and 671\n",
      "  and 672\n",
      "N and 673\n",
      "E and 674\n",
      "F and 675\n",
      "T and 676\n",
      ". and 677\n",
      "S and 678\n",
      "e and 679\n",
      "n and 680\n",
      "d and 681\n",
      "e and 682\n",
      "r and 683\n",
      ": and 684\n",
      "P and 685\n",
      "R and 686\n",
      "I and 687\n",
      "Y and 688\n",
      "A and 689\n",
      "N and 690\n",
      "K and 691\n",
      "A and 692\n",
      "  and 693\n",
      "M and 694\n",
      "A and 695\n",
      "N and 696\n",
      "I and 697\n",
      "S and 698\n",
      "H and 699\n",
      "  and 700\n",
      "R and 701\n",
      "A and 702\n",
      "B and 703\n",
      "H and 704\n",
      ". and 705\n",
      "U and 706\n",
      "T and 707\n",
      "R and 708\n",
      ": and 709\n",
      "N and 710\n",
      "0 and 711\n",
      "9 and 712\n",
      "6 and 713\n",
      "2 and 714\n",
      "1 and 715\n",
      "1 and 716\n",
      "4 and 717\n",
      "6 and 718\n",
      "5 and 719\n",
      "5 and 720\n",
      "0 and 721\n",
      "9 and 722\n",
      "6 and 723\n",
      "9 and 724\n",
      "2 and 725\n",
      "  and 726\n",
      "A and 727\n",
      "v and 728\n",
      "l and 729\n",
      "  and 730\n",
      "B and 731\n",
      "a and 732\n",
      "l and 733\n",
      "  and 734\n",
      "R and 735\n",
      "s and 736\n",
      ": and 737\n",
      "1 and 738\n",
      "3 and 739\n",
      "4 and 740\n",
      "2 and 741\n",
      "2 and 742\n",
      ". and 743\n",
      "8 and 744\n",
      "7 and 745\n",
      "  and 746\n",
      "- and 747\n",
      "U and 748\n",
      "n and 749\n",
      "i and 750\n",
      "o and 751\n",
      "n and 752\n",
      "  and 753\n",
      "B and 754\n",
      "a and 755\n",
      "n and 756\n",
      "k and 757\n",
      "  and 758\n",
      "o and 759\n",
      "f and 760\n",
      "  and 761\n",
      "I and 762\n",
      "n and 763\n",
      "d and 764\n",
      "i and 765\n",
      "a and 766\n",
      "Y and 767\n",
      "o and 768\n",
      "u and 769\n",
      "r and 770\n",
      "  and 771\n",
      "S and 772\n",
      "B and 773\n",
      "  and 774\n",
      "A and 775\n",
      "/ and 776\n",
      "c and 777\n",
      "  and 778\n",
      "* and 779\n",
      "* and 780\n",
      "0 and 781\n",
      "6 and 782\n",
      "1 and 783\n",
      "2 and 784\n",
      "1 and 785\n",
      "  and 786\n",
      "i and 787\n",
      "s and 788\n",
      "  and 789\n",
      "C and 790\n",
      "r and 791\n",
      "e and 792\n",
      "d and 793\n",
      "i and 794\n",
      "t and 795\n",
      "e and 796\n",
      "d and 797\n",
      "  and 798\n",
      "f and 799\n",
      "o and 800\n",
      "r and 801\n",
      "  and 802\n",
      "R and 803\n",
      "s and 804\n",
      ". and 805\n",
      "3 and 806\n",
      "0 and 807\n",
      "0 and 808\n",
      "0 and 809\n",
      "  and 810\n",
      "o and 811\n",
      "n and 812\n",
      "  and 813\n",
      "0 and 814\n",
      "6 and 815\n",
      "- and 816\n",
      "0 and 817\n",
      "5 and 818\n",
      "- and 819\n",
      "2 and 820\n",
      "0 and 821\n",
      "2 and 822\n",
      "1 and 823\n",
      "  and 824\n",
      "2 and 825\n",
      "2 and 826\n",
      ": and 827\n",
      "3 and 828\n",
      "1 and 829\n",
      ": and 830\n",
      "3 and 831\n",
      "6 and 832\n",
      "  and 833\n",
      "b and 834\n",
      "y and 835\n",
      "  and 836\n",
      "N and 837\n",
      "E and 838\n",
      "F and 839\n",
      "T and 840\n",
      ". and 841\n",
      "S and 842\n",
      "e and 843\n",
      "n and 844\n",
      "d and 845\n",
      "e and 846\n",
      "r and 847\n",
      ": and 848\n",
      "P and 849\n",
      "R and 850\n",
      "I and 851\n",
      "Y and 852\n",
      "A and 853\n",
      "N and 854\n",
      "K and 855\n",
      "A and 856\n",
      "  and 857\n",
      "M and 858\n",
      "A and 859\n",
      "N and 860\n",
      "I and 861\n",
      "S and 862\n",
      "H and 863\n",
      "  and 864\n",
      "R and 865\n",
      "A and 866\n",
      "B and 867\n",
      "H and 868\n",
      ". and 869\n",
      "U and 870\n",
      "T and 871\n",
      "R and 872\n",
      ": and 873\n",
      "N and 874\n",
      "1 and 875\n",
      "2 and 876\n",
      "6 and 877\n",
      "2 and 878\n",
      "1 and 879\n",
      "1 and 880\n",
      "4 and 881\n",
      "9 and 882\n",
      "6 and 883\n",
      "9 and 884\n",
      "5 and 885\n",
      "0 and 886\n",
      "7 and 887\n",
      "6 and 888\n",
      "5 and 889\n",
      "  and 890\n",
      "A and 891\n",
      "v and 892\n",
      "l and 893\n",
      "  and 894\n",
      "B and 895\n",
      "a and 896\n",
      "l and 897\n",
      "  and 898\n",
      "R and 899\n",
      "s and 900\n",
      ": and 901\n",
      "1 and 902\n",
      "6 and 903\n",
      "0 and 904\n",
      "2 and 905\n",
      "2 and 906\n",
      ". and 907\n",
      "8 and 908\n",
      "7 and 909\n",
      "  and 910\n",
      "- and 911\n",
      "U and 912\n",
      "n and 913\n",
      "i and 914\n",
      "o and 915\n",
      "n and 916\n",
      "  and 917\n",
      "B and 918\n",
      "a and 919\n",
      "n and 920\n",
      "k and 921\n",
      "  and 922\n",
      "o and 923\n",
      "f and 924\n",
      "  and 925\n",
      "I and 926\n",
      "n and 927\n",
      "d and 928\n",
      "i and 929\n",
      "a and 930\n",
      "R and 931\n",
      "s and 932\n",
      "4 and 933\n",
      "0 and 934\n",
      "0 and 935\n",
      ". and 936\n",
      "0 and 937\n",
      "  and 938\n",
      "d and 939\n",
      "e and 940\n",
      "b and 941\n",
      "i and 942\n",
      "t and 943\n",
      "e and 944\n",
      "d and 945\n",
      "@ and 946\n",
      "S and 947\n",
      "B and 948\n",
      "I and 949\n",
      "  and 950\n",
      "U and 951\n",
      "P and 952\n",
      "I and 953\n",
      "  and 954\n",
      "f and 955\n",
      "r and 956\n",
      "m and 957\n",
      "  and 958\n",
      "A and 959\n",
      "/ and 960\n",
      "c and 961\n",
      "X and 962\n",
      "6 and 963\n",
      "0 and 964\n",
      "7 and 965\n",
      "0 and 966\n",
      "  and 967\n",
      "o and 968\n",
      "n and 969\n",
      "  and 970\n",
      "1 and 971\n",
      "9 and 972\n",
      "M and 973\n",
      "a and 974\n",
      "y and 975\n",
      "2 and 976\n",
      "1 and 977\n",
      "  and 978\n",
      "R and 979\n",
      "e and 980\n",
      "f and 981\n",
      "N and 982\n",
      "o and 983\n",
      "  and 984\n",
      "1 and 985\n",
      "1 and 986\n",
      "3 and 987\n",
      "9 and 988\n",
      "2 and 989\n",
      "0 and 990\n",
      "3 and 991\n",
      "2 and 992\n",
      "5 and 993\n",
      "1 and 994\n",
      "1 and 995\n",
      "1 and 996\n",
      ". and 997\n",
      "  and 998\n",
      "I and 999\n",
      "f and 1000\n",
      "  and 1001\n",
      "n and 1002\n",
      "o and 1003\n",
      "t and 1004\n",
      "  and 1005\n",
      "d and 1006\n",
      "o and 1007\n",
      "n and 1008\n",
      "e and 1009\n",
      "  and 1010\n",
      "b and 1011\n",
      "y and 1012\n",
      "  and 1013\n",
      "u and 1014\n",
      ", and 1015\n",
      "  and 1016\n",
      "f and 1017\n",
      "w and 1018\n",
      "d and 1019\n",
      "  and 1020\n",
      "t and 1021\n",
      "h and 1022\n",
      "i and 1023\n",
      "s and 1024\n",
      "  and 1025\n",
      "S and 1026\n",
      "M and 1027\n",
      "S and 1028\n",
      "  and 1029\n",
      "t and 1030\n",
      "o and 1031\n",
      "  and 1032\n",
      "9 and 1033\n",
      "2 and 1034\n",
      "2 and 1035\n",
      "3 and 1036\n",
      "0 and 1037\n",
      "0 and 1038\n",
      "8 and 1039\n",
      "3 and 1040\n",
      "3 and 1041\n",
      "3 and 1042\n",
      "/ and 1043\n",
      "C and 1044\n",
      "a and 1045\n",
      "l and 1046\n",
      "l and 1047\n",
      "  and 1048\n",
      "1 and 1049\n",
      "8 and 1050\n",
      "0 and 1051\n",
      "0 and 1052\n",
      "1 and 1053\n",
      "1 and 1054\n",
      "1 and 1055\n",
      "1 and 1056\n",
      "0 and 1057\n",
      "9 and 1058\n",
      "  and 1059\n",
      "o and 1060\n",
      "r and 1061\n",
      "  and 1062\n",
      "0 and 1063\n",
      "9 and 1064\n",
      "4 and 1065\n",
      "4 and 1066\n",
      "9 and 1067\n",
      "1 and 1068\n",
      "1 and 1069\n",
      "2 and 1070\n",
      "2 and 1071\n",
      "1 and 1072\n",
      "1 and 1073\n",
      "  and 1074\n",
      "t and 1075\n",
      "o and 1076\n",
      "  and 1077\n",
      "b and 1078\n",
      "l and 1079\n",
      "o and 1080\n",
      "c and 1081\n",
      "k and 1082\n",
      "  and 1083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U and 1084\n",
      "P and 1085\n",
      "I and 1086\n",
      "Y and 1087\n",
      "o and 1088\n",
      "u and 1089\n",
      "r and 1090\n",
      "  and 1091\n",
      "a and 1092\n",
      "/ and 1093\n",
      "c and 1094\n",
      "  and 1095\n",
      "n and 1096\n",
      "o and 1097\n",
      ". and 1098\n",
      "  and 1099\n",
      "X and 1100\n",
      "X and 1101\n",
      "X and 1102\n",
      "X and 1103\n",
      "X and 1104\n",
      "X and 1105\n",
      "X and 1106\n",
      "X and 1107\n",
      "X and 1108\n",
      "X and 1109\n",
      "X and 1110\n",
      "6 and 1111\n",
      "1 and 1112\n",
      "2 and 1113\n",
      "1 and 1114\n",
      "  and 1115\n",
      "i and 1116\n",
      "s and 1117\n",
      "  and 1118\n",
      "d and 1119\n",
      "e and 1120\n",
      "b and 1121\n",
      "i and 1122\n",
      "t and 1123\n",
      "e and 1124\n",
      "d and 1125\n",
      "  and 1126\n",
      "f and 1127\n",
      "o and 1128\n",
      "r and 1129\n",
      "  and 1130\n",
      "R and 1131\n",
      "s and 1132\n",
      ". and 1133\n",
      "  and 1134\n",
      "1 and 1135\n",
      "8 and 1136\n",
      "3 and 1137\n",
      "6 and 1138\n",
      ". and 1139\n",
      "0 and 1140\n",
      "0 and 1141\n",
      "  and 1142\n",
      "o and 1143\n",
      "n and 1144\n",
      "  and 1145\n",
      "0 and 1146\n",
      "6 and 1147\n",
      "  and 1148\n",
      "A and 1149\n",
      "p and 1150\n",
      "r and 1151\n",
      "  and 1152\n",
      "2 and 1153\n",
      "0 and 1154\n",
      "2 and 1155\n",
      "1 and 1156\n",
      ", and 1157\n",
      "  and 1158\n",
      "2 and 1159\n",
      "2 and 1160\n",
      ": and 1161\n",
      "4 and 1162\n",
      "5 and 1163\n",
      ": and 1164\n",
      "3 and 1165\n",
      "9 and 1166\n",
      "  and 1167\n",
      "  and 1168\n",
      "( and 1169\n",
      "U and 1170\n",
      "P and 1171\n",
      "I and 1172\n",
      "  and 1173\n",
      "R and 1174\n",
      "e and 1175\n",
      "f and 1176\n",
      "  and 1177\n",
      "n and 1178\n",
      "o and 1179\n",
      "  and 1180\n",
      "1 and 1181\n",
      "0 and 1182\n",
      "9 and 1183\n",
      "6 and 1184\n",
      "2 and 1185\n",
      "2 and 1186\n",
      "4 and 1187\n",
      "1 and 1188\n",
      "3 and 1189\n",
      "5 and 1190\n",
      "0 and 1191\n",
      "7 and 1192\n",
      ") and 1193\n",
      ". and 1194\n",
      "D and 1195\n",
      "e and 1196\n",
      "a and 1197\n",
      "r and 1198\n",
      "  and 1199\n",
      "C and 1200\n",
      "u and 1201\n",
      "s and 1202\n",
      "t and 1203\n",
      "o and 1204\n",
      "m and 1205\n",
      "e and 1206\n",
      "r and 1207\n",
      ", and 1208\n",
      "  and 1209\n",
      "I and 1210\n",
      "N and 1211\n",
      "R and 1212\n",
      "  and 1213\n",
      "8 and 1214\n",
      ", and 1215\n",
      "4 and 1216\n",
      "0 and 1217\n",
      "0 and 1218\n",
      ". and 1219\n",
      "0 and 1220\n",
      "0 and 1221\n",
      "  and 1222\n",
      "c and 1223\n",
      "r and 1224\n",
      "e and 1225\n",
      "d and 1226\n",
      "i and 1227\n",
      "t and 1228\n",
      "e and 1229\n",
      "d and 1230\n",
      "  and 1231\n",
      "t and 1232\n",
      "o and 1233\n",
      "  and 1234\n",
      "y and 1235\n",
      "o and 1236\n",
      "u and 1237\n",
      "r and 1238\n",
      "  and 1239\n",
      "A and 1240\n",
      "/ and 1241\n",
      "c and 1242\n",
      "  and 1243\n",
      "N and 1244\n",
      "o and 1245\n",
      "  and 1246\n",
      "X and 1247\n",
      "X and 1248\n",
      "6 and 1249\n",
      "0 and 1250\n",
      "7 and 1251\n",
      "0 and 1252\n",
      "  and 1253\n",
      "o and 1254\n",
      "n and 1255\n",
      "  and 1256\n",
      "1 and 1257\n",
      "4 and 1258\n",
      "/ and 1259\n",
      "0 and 1260\n",
      "5 and 1261\n",
      "/ and 1262\n",
      "2 and 1263\n",
      "0 and 1264\n",
      "2 and 1265\n",
      "1 and 1266\n",
      "  and 1267\n",
      "t and 1268\n",
      "h and 1269\n",
      "r and 1270\n",
      "o and 1271\n",
      "u and 1272\n",
      "g and 1273\n",
      "h and 1274\n",
      "  and 1275\n",
      "N and 1276\n",
      "E and 1277\n",
      "F and 1278\n",
      "T and 1279\n",
      "  and 1280\n",
      "w and 1281\n",
      "i and 1282\n",
      "t and 1283\n",
      "h and 1284\n",
      "  and 1285\n",
      "U and 1286\n",
      "T and 1287\n",
      "R and 1288\n",
      "  and 1289\n",
      "P and 1290\n",
      "1 and 1291\n",
      "3 and 1292\n",
      "4 and 1293\n",
      "2 and 1294\n",
      "1 and 1295\n",
      "0 and 1296\n",
      "1 and 1297\n",
      "0 and 1298\n",
      "8 and 1299\n",
      "5 and 1300\n",
      "2 and 1301\n",
      "5 and 1302\n",
      "6 and 1303\n",
      "2 and 1304\n",
      "2 and 1305\n",
      "  and 1306\n",
      "b and 1307\n",
      "y and 1308\n",
      "  and 1309\n",
      "S and 1310\n",
      "A and 1311\n",
      "I and 1312\n",
      "  and 1313\n",
      "I and 1314\n",
      "N and 1315\n",
      "S and 1316\n",
      "P and 1317\n",
      "E and 1318\n",
      "C and 1319\n",
      "T and 1320\n",
      "I and 1321\n",
      "O and 1322\n",
      "N and 1323\n",
      "  and 1324\n",
      "S and 1325\n",
      "E and 1326\n",
      "R and 1327\n",
      "V and 1328\n",
      "I and 1329\n",
      ", and 1330\n",
      "  and 1331\n",
      "I and 1332\n",
      "N and 1333\n",
      "F and 1334\n",
      "O and 1335\n",
      ": and 1336\n",
      "  and 1337\n",
      "S and 1338\n",
      "a and 1339\n",
      "l and 1340\n",
      "a and 1341\n",
      "r and 1342\n",
      "y and 1343\n",
      "f and 1344\n",
      "o and 1345\n",
      "r and 1346\n",
      "t and 1347\n",
      "h and 1348\n",
      "e and 1349\n",
      "m and 1350\n",
      "o and 1351\n",
      "n and 1352\n",
      "t and 1353\n",
      "h and 1354\n",
      "o and 1355\n",
      "f and 1356\n",
      "A and 1357\n",
      "p and 1358\n",
      "r and 1359\n",
      "i and 1360\n",
      "l and 1361\n",
      "2 and 1362\n",
      "0 and 1363\n",
      "2 and 1364\n",
      "1 and 1365\n",
      "- and 1366\n",
      "S and 1367\n",
      "B and 1368\n",
      "I and 1369\n",
      "D and 1370\n",
      "e and 1371\n",
      "a and 1372\n",
      "r and 1373\n",
      "  and 1374\n",
      "S and 1375\n",
      "B and 1376\n",
      "I and 1377\n",
      "  and 1378\n",
      "C and 1379\n",
      "u and 1380\n",
      "s and 1381\n",
      "t and 1382\n",
      "o and 1383\n",
      "m and 1384\n",
      "e and 1385\n",
      "r and 1386\n",
      ", and 1387\n",
      "  and 1388\n",
      "R and 1389\n",
      "s and 1390\n",
      ". and 1391\n",
      "1 and 1392\n",
      "0 and 1393\n",
      "0 and 1394\n",
      "0 and 1395\n",
      "  and 1396\n",
      "w and 1397\n",
      "i and 1398\n",
      "t and 1399\n",
      "h and 1400\n",
      "d and 1401\n",
      "r and 1402\n",
      "a and 1403\n",
      "w and 1404\n",
      "n and 1405\n",
      "  and 1406\n",
      "a and 1407\n",
      "t and 1408\n",
      "  and 1409\n",
      "I and 1410\n",
      "C and 1411\n",
      "I and 1412\n",
      "  and 1413\n",
      "A and 1414\n",
      "T and 1415\n",
      "M and 1416\n",
      "  and 1417\n",
      "S and 1418\n",
      "P and 1419\n",
      "C and 1420\n",
      "N and 1421\n",
      "F and 1422\n",
      "3 and 1423\n",
      "0 and 1424\n",
      "8 and 1425\n",
      "  and 1426\n",
      "f and 1427\n",
      "r and 1428\n",
      "o and 1429\n",
      "m and 1430\n",
      "  and 1431\n",
      "A and 1432\n",
      "/ and 1433\n",
      "c and 1434\n",
      "X and 1435\n",
      "6 and 1436\n",
      "0 and 1437\n",
      "7 and 1438\n",
      "0 and 1439\n",
      "  and 1440\n",
      "o and 1441\n",
      "n and 1442\n",
      "  and 1443\n",
      "1 and 1444\n",
      "9 and 1445\n",
      "M and 1446\n",
      "a and 1447\n",
      "y and 1448\n",
      "2 and 1449\n",
      "1 and 1450\n",
      "  and 1451\n",
      "T and 1452\n",
      "r and 1453\n",
      "a and 1454\n",
      "n and 1455\n",
      "s and 1456\n",
      "a and 1457\n",
      "c and 1458\n",
      "t and 1459\n",
      "i and 1460\n",
      "o and 1461\n",
      "n and 1462\n",
      "  and 1463\n",
      "N and 1464\n",
      "u and 1465\n",
      "m and 1466\n",
      "b and 1467\n",
      "e and 1468\n",
      "r and 1469\n",
      "  and 1470\n",
      "1 and 1471\n",
      "1 and 1472\n",
      "3 and 1473\n",
      "9 and 1474\n",
      "0 and 1475\n",
      "8 and 1476\n",
      "0 and 1477\n",
      "0 and 1478\n",
      "6 and 1479\n",
      "3 and 1480\n",
      "1 and 1481\n",
      "7 and 1482\n",
      ". and 1483\n",
      "  and 1484\n",
      "A and 1485\n",
      "v and 1486\n",
      "a and 1487\n",
      "i and 1488\n",
      "l and 1489\n",
      "a and 1490\n",
      "b and 1491\n",
      "l and 1492\n",
      "e and 1493\n",
      "  and 1494\n",
      "B and 1495\n",
      "a and 1496\n",
      "l and 1497\n",
      "a and 1498\n",
      "n and 1499\n",
      "c and 1500\n",
      "e and 1501\n",
      "  and 1502\n",
      "R and 1503\n",
      "s and 1504\n",
      ". and 1505\n",
      "9 and 1506\n",
      "5 and 1507\n",
      "7 and 1508\n",
      "5 and 1509\n",
      ". and 1510\n",
      "  and 1511\n",
      "I and 1512\n",
      "f and 1513\n",
      "  and 1514\n",
      "n and 1515\n",
      "o and 1516\n",
      "t and 1517\n",
      "  and 1518\n",
      "w and 1519\n",
      "i and 1520\n",
      "t and 1521\n",
      "h and 1522\n",
      "d and 1523\n",
      "r and 1524\n",
      "a and 1525\n",
      "w and 1526\n",
      "n and 1527\n",
      "  and 1528\n",
      "b and 1529\n",
      "y and 1530\n",
      "  and 1531\n",
      "y and 1532\n",
      "o and 1533\n",
      "u and 1534\n",
      ", and 1535\n",
      "  and 1536\n",
      "f and 1537\n",
      "o and 1538\n",
      "r and 1539\n",
      "w and 1540\n",
      "a and 1541\n",
      "r and 1542\n",
      "d and 1543\n",
      "  and 1544\n",
      "t and 1545\n",
      "h and 1546\n",
      "i and 1547\n",
      "s and 1548\n",
      "  and 1549\n",
      "S and 1550\n",
      "M and 1551\n",
      "S and 1552\n",
      "  and 1553\n",
      "t and 1554\n",
      "o and 1555\n",
      "  and 1556\n",
      "9 and 1557\n",
      "2 and 1558\n",
      "2 and 1559\n",
      "3 and 1560\n",
      "0 and 1561\n",
      "0 and 1562\n",
      "8 and 1563\n",
      "3 and 1564\n",
      "3 and 1565\n",
      "3 and 1566\n",
      "  and 1567\n",
      "/ and 1568\n",
      "  and 1569\n",
      "c and 1570\n",
      "a and 1571\n",
      "l and 1572\n",
      "l and 1573\n",
      "  and 1574\n",
      "1 and 1575\n",
      "8 and 1576\n",
      "0 and 1577\n",
      "0 and 1578\n",
      "1 and 1579\n",
      "1 and 1580\n",
      "1 and 1581\n",
      "1 and 1582\n",
      "0 and 1583\n",
      "9 and 1584\n",
      "  and 1585\n",
      "o and 1586\n",
      "r and 1587\n",
      "  and 1588\n",
      "0 and 1589\n",
      "9 and 1590\n",
      "4 and 1591\n",
      "4 and 1592\n",
      "9 and 1593\n",
      "1 and 1594\n",
      "1 and 1595\n",
      "2 and 1596\n",
      "2 and 1597\n",
      "1 and 1598\n",
      "1 and 1599\n",
      "  and 1600\n",
      "t and 1601\n",
      "o and 1602\n",
      "  and 1603\n",
      "b and 1604\n",
      "l and 1605\n",
      "o and 1606\n",
      "c and 1607\n",
      "k and 1608\n",
      "  and 1609\n",
      "y and 1610\n",
      "o and 1611\n",
      "u and 1612\n",
      "r and 1613\n",
      "  and 1614\n",
      "c and 1615\n",
      "a and 1616\n",
      "r and 1617\n",
      "d and 1618\n",
      ". and 1619\n",
      "  and 1620\n",
      "D and 1621\n",
      "o and 1622\n",
      "w and 1623\n",
      "n and 1624\n",
      "l and 1625\n",
      "o and 1626\n",
      "a and 1627\n",
      "d and 1628\n",
      "  and 1629\n",
      "Y and 1630\n",
      "O and 1631\n",
      "N and 1632\n",
      "O and 1633\n",
      "  and 1634\n",
      "S and 1635\n",
      "B and 1636\n",
      "I and 1637\n",
      ". and 1638\n",
      "  and 1639\n",
      "U and 1640\n",
      "s and 1641\n",
      "e and 1642\n",
      "  and 1643\n",
      "S and 1644\n",
      "B and 1645\n",
      "I and 1646\n",
      "  and 1647\n",
      "A and 1648\n",
      "T and 1649\n",
      "M and 1650\n",
      "s and 1651\n",
      ". and 1652\n",
      "D and 1653\n",
      "e and 1654\n",
      "a and 1655\n",
      "r and 1656\n",
      "  and 1657\n",
      "C and 1658\n",
      "u and 1659\n",
      "s and 1660\n",
      "t and 1661\n",
      "o and 1662\n",
      "m and 1663\n",
      "e and 1664\n",
      "r and 1665\n",
      ", and 1666\n",
      "  and 1667\n",
      "y and 1668\n",
      "o and 1669\n",
      "u and 1670\n",
      "r and 1671\n",
      "  and 1672\n",
      "A and 1673\n",
      "c and 1674\n",
      "c and 1675\n",
      "o and 1676\n",
      "u and 1677\n",
      "n and 1678\n",
      "t and 1679\n",
      "  and 1680\n",
      "X and 1681\n",
      "X and 1682\n",
      "5 and 1683\n",
      "6 and 1684\n",
      "0 and 1685\n",
      "5 and 1686\n",
      "  and 1687\n",
      "h and 1688\n",
      "a and 1689\n",
      "s and 1690\n",
      "  and 1691\n",
      "b and 1692\n",
      "e and 1693\n",
      "e and 1694\n",
      "n and 1695\n",
      "  and 1696\n",
      "c and 1697\n",
      "r and 1698\n",
      "e and 1699\n",
      "d and 1700\n",
      "i and 1701\n",
      "t and 1702\n",
      "e and 1703\n",
      "d and 1704\n",
      "  and 1705\n",
      "w and 1706\n",
      "i and 1707\n",
      "t and 1708\n",
      "h and 1709\n",
      "  and 1710\n",
      "I and 1711\n",
      "N and 1712\n",
      "R and 1713\n",
      "  and 1714\n",
      "7 and 1715\n",
      "0 and 1716\n",
      ", and 1717\n",
      "5 and 1718\n",
      "0 and 1719\n",
      "3 and 1720\n",
      ". and 1721\n",
      "0 and 1722\n",
      "0 and 1723\n",
      "  and 1724\n",
      "o and 1725\n",
      "n and 1726\n",
      "  and 1727\n",
      "0 and 1728\n",
      "6 and 1729\n",
      "- and 1730\n",
      "N and 1731\n",
      "o and 1732\n",
      "v and 1733\n",
      "- and 1734\n",
      "1 and 1735\n",
      "8 and 1736\n",
      ". and 1737\n",
      "  and 1738\n",
      "I and 1739\n",
      "n and 1740\n",
      "f and 1741\n",
      "o and 1742\n",
      ": and 1743\n",
      "  and 1744\n",
      "N and 1745\n",
      "E and 1746\n",
      "F and 1747\n",
      "T and 1748\n",
      "- and 1749\n",
      "A and 1750\n",
      "X and 1751\n",
      "I and 1752\n",
      "C and 1753\n",
      "1 and 1754\n",
      "8 and 1755\n",
      "3 and 1756\n",
      "1 and 1757\n",
      "0 and 1758\n",
      "4 and 1759\n",
      "1 and 1760\n",
      "3 and 1761\n",
      "9 and 1762\n",
      "4 and 1763\n",
      "2 and 1764\n",
      "5 and 1765\n",
      "- and 1766\n",
      "T and 1767\n",
      "H and 1768\n",
      "O and 1769\n",
      "U and 1770\n",
      "G and 1771\n",
      "H and 1772\n",
      ". and 1773\n",
      "  and 1774\n",
      "T and 1775\n",
      "h and 1776\n",
      "e and 1777\n",
      "  and 1778\n",
      "A and 1779\n",
      "v and 1780\n",
      "a and 1781\n",
      "i and 1782\n",
      "l and 1783\n",
      "a and 1784\n",
      "b and 1785\n",
      "l and 1786\n",
      "e and 1787\n",
      "  and 1788\n",
      "B and 1789\n",
      "a and 1790\n",
      "l and 1791\n",
      "a and 1792\n",
      "n and 1793\n",
      "c and 1794\n",
      "e and 1795\n",
      "  and 1796\n",
      "i and 1797\n",
      "s and 1798\n",
      "  and 1799\n",
      "I and 1800\n",
      "N and 1801\n",
      "R and 1802\n",
      "  and 1803\n",
      "7 and 1804\n",
      "4 and 1805\n",
      ", and 1806\n",
      "0 and 1807\n",
      "1 and 1808\n",
      "7 and 1809\n",
      ". and 1810\n",
      "6 and 1811\n",
      "1 and 1812\n",
      ". and 1813\n",
      "D and 1814\n",
      "e and 1815\n",
      "a and 1816\n",
      "r and 1817\n",
      "  and 1818\n",
      "C and 1819\n",
      "u and 1820\n",
      "s and 1821\n",
      "t and 1822\n",
      "o and 1823\n",
      "m and 1824\n",
      "e and 1825\n",
      "r and 1826\n",
      ", and 1827\n",
      "  and 1828\n",
      "y and 1829\n",
      "o and 1830\n",
      "u and 1831\n",
      "r and 1832\n",
      "  and 1833\n",
      "A and 1834\n",
      "c and 1835\n",
      "c and 1836\n",
      "o and 1837\n",
      "u and 1838\n",
      "n and 1839\n",
      "t and 1840\n",
      "  and 1841\n",
      "X and 1842\n",
      "X and 1843\n",
      "5 and 1844\n",
      "6 and 1845\n",
      "0 and 1846\n",
      "5 and 1847\n",
      "  and 1848\n",
      "h and 1849\n",
      "a and 1850\n",
      "s and 1851\n",
      "  and 1852\n",
      "b and 1853\n",
      "e and 1854\n",
      "e and 1855\n",
      "n and 1856\n",
      "  and 1857\n",
      "d and 1858\n",
      "e and 1859\n",
      "b and 1860\n",
      "i and 1861\n",
      "t and 1862\n",
      "e and 1863\n",
      "d and 1864\n",
      "  and 1865\n",
      "w and 1866\n",
      "i and 1867\n",
      "t and 1868\n",
      "h and 1869\n",
      "  and 1870\n",
      "I and 1871\n",
      "N and 1872\n",
      "R and 1873\n",
      "  and 1874\n",
      "3 and 1875\n",
      "4 and 1876\n",
      ", and 1877\n",
      "7 and 1878\n",
      "6 and 1879\n",
      "0 and 1880\n",
      ". and 1881\n",
      "0 and 1882\n",
      "0 and 1883\n",
      "  and 1884\n",
      "o and 1885\n",
      "n and 1886\n",
      "  and 1887\n",
      "0 and 1888\n",
      "6 and 1889\n",
      "- and 1890\n",
      "N and 1891\n",
      "o and 1892\n",
      "v and 1893\n",
      "- and 1894\n",
      "1 and 1895\n",
      "8 and 1896\n",
      ". and 1897\n",
      "  and 1898\n",
      "I and 1899\n",
      "n and 1900\n",
      "f and 1901\n",
      "o and 1902\n",
      ": and 1903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  and 1904\n",
      "B and 1905\n",
      "I and 1906\n",
      "L and 1907\n",
      "* and 1908\n",
      "D and 1909\n",
      "T and 1910\n",
      "A and 1911\n",
      "X and 1912\n",
      "* and 1913\n",
      "0 and 1914\n",
      "0 and 1915\n",
      "1 and 1916\n",
      "5 and 1917\n",
      "7 and 1918\n",
      "2 and 1919\n",
      "1 and 1920\n",
      "9 and 1921\n",
      "8 and 1922\n",
      "7 and 1923\n",
      "9 and 1924\n",
      "1 and 1925\n",
      "* and 1926\n",
      "D and 1927\n",
      "T and 1928\n",
      "A and 1929\n",
      "X and 1930\n",
      "* and 1931\n",
      "C and 1932\n",
      ". and 1933\n",
      "  and 1934\n",
      "T and 1935\n",
      "h and 1936\n",
      "e and 1937\n",
      "  and 1938\n",
      "A and 1939\n",
      "v and 1940\n",
      "a and 1941\n",
      "i and 1942\n",
      "l and 1943\n",
      "a and 1944\n",
      "b and 1945\n",
      "l and 1946\n",
      "e and 1947\n",
      "  and 1948\n",
      "B and 1949\n",
      "a and 1950\n",
      "l and 1951\n",
      "a and 1952\n",
      "n and 1953\n",
      "c and 1954\n",
      "e and 1955\n",
      "  and 1956\n",
      "i and 1957\n",
      "s and 1958\n",
      "  and 1959\n",
      "I and 1960\n",
      "N and 1961\n",
      "R and 1962\n",
      "  and 1963\n",
      "3 and 1964\n",
      "9 and 1965\n",
      ", and 1966\n",
      "2 and 1967\n",
      "5 and 1968\n",
      "7 and 1969\n",
      ". and 1970\n",
      "6 and 1971\n",
      "1 and 1972\n",
      ". and 1973\n",
      "F and 1974\n",
      "o and 1975\n",
      "r and 1976\n",
      "  and 1977\n",
      "d and 1978\n",
      "i and 1979\n",
      "s and 1980\n",
      "p and 1981\n",
      "u and 1982\n",
      "t and 1983\n",
      "e and 1984\n",
      ", and 1985\n",
      "c and 1986\n",
      "a and 1987\n",
      "l and 1988\n",
      "l and 1989\n",
      "  and 1990\n",
      "0 and 1991\n",
      "4 and 1992\n",
      "0 and 1993\n",
      "3 and 1994\n",
      "3 and 1995\n",
      "6 and 1996\n",
      "6 and 1997\n",
      "7 and 1998\n",
      "7 and 1999\n",
      "7 and 2000\n",
      "7 and 2001\n",
      ". and 2002\n",
      "A and 2003\n",
      "n and 2004\n",
      "  and 2005\n",
      "a and 2006\n",
      "m and 2007\n",
      "o and 2008\n",
      "u and 2009\n",
      "n and 2010\n",
      "t and 2011\n",
      "  and 2012\n",
      "o and 2013\n",
      "f and 2014\n",
      "  and 2015\n",
      "1 and 2016\n",
      "0 and 2017\n",
      "8 and 2018\n",
      "1 and 2019\n",
      "  and 2020\n",
      "I and 2021\n",
      "N and 2022\n",
      "R and 2023\n",
      "  and 2024\n",
      "h and 2025\n",
      "a and 2026\n",
      "s and 2027\n",
      "  and 2028\n",
      "b and 2029\n",
      "e and 2030\n",
      "e and 2031\n",
      "n and 2032\n",
      "  and 2033\n",
      "d and 2034\n",
      "e and 2035\n",
      "b and 2036\n",
      "i and 2037\n",
      "t and 2038\n",
      "e and 2039\n",
      "d and 2040\n",
      "  and 2041\n",
      "t and 2042\n",
      "o and 2043\n",
      "  and 2044\n",
      "A and 2045\n",
      "/ and 2046\n",
      "c and 2047\n",
      "  and 2048\n",
      "n and 2049\n",
      "o and 2050\n",
      "  and 2051\n",
      "X and 2052\n",
      "X and 2053\n",
      "X and 2054\n",
      "X and 2055\n",
      "X and 2056\n",
      "X and 2057\n",
      "X and 2058\n",
      "1 and 2059\n",
      "0 and 2060\n",
      "3 and 2061\n",
      "0 and 2062\n",
      "6 and 2063\n",
      "9 and 2064\n",
      "1 and 2065\n",
      "  and 2066\n",
      "b and 2067\n",
      "y and 2068\n",
      "  and 2069\n",
      "F and 2070\n",
      "u and 2071\n",
      "n and 2072\n",
      "d and 2073\n",
      "  and 2074\n",
      "T and 2075\n",
      "r and 2076\n",
      "a and 2077\n",
      "n and 2078\n",
      "s and 2079\n",
      "f and 2080\n",
      "e and 2081\n",
      "r and 2082\n",
      "  and 2083\n",
      "o and 2084\n",
      "n and 2085\n",
      "  and 2086\n",
      "0 and 2087\n",
      "9 and 2088\n",
      "- and 2089\n",
      "N and 2090\n",
      "O and 2091\n",
      "V and 2092\n",
      "- and 2093\n",
      "1 and 2094\n",
      "8 and 2095\n",
      "  and 2096\n",
      "1 and 2097\n",
      "0 and 2098\n",
      ": and 2099\n",
      "3 and 2100\n",
      "6 and 2101\n",
      ": and 2102\n",
      "3 and 2103\n",
      "0 and 2104\n",
      ". and 2105\n",
      "  and 2106\n",
      "N and 2107\n",
      "o and 2108\n",
      "w and 2109\n",
      "  and 2110\n",
      "C and 2111\n",
      "l and 2112\n",
      "e and 2113\n",
      "a and 2114\n",
      "r and 2115\n",
      "  and 2116\n",
      "b and 2117\n",
      "a and 2118\n",
      "l and 2119\n",
      "a and 2120\n",
      "n and 2121\n",
      "c and 2122\n",
      "e and 2123\n",
      "  and 2124\n",
      "i and 2125\n",
      "s and 2126\n",
      "  and 2127\n",
      "C and 2128\n",
      "r and 2129\n",
      "e and 2130\n",
      "d and 2131\n",
      "i and 2132\n",
      "t and 2133\n",
      "  and 2134\n",
      "I and 2135\n",
      "N and 2136\n",
      "R and 2137\n",
      "  and 2138\n",
      "1 and 2139\n",
      "0 and 2140\n",
      "5 and 2141\n",
      "3 and 2142\n",
      "5 and 2143\n",
      ". and 2144\n",
      "9 and 2145\n",
      "4 and 2146\n",
      "D and 2147\n",
      "e and 2148\n",
      "a and 2149\n",
      "r and 2150\n",
      "  and 2151\n",
      "C and 2152\n",
      "u and 2153\n",
      "s and 2154\n",
      "t and 2155\n",
      "o and 2156\n",
      "m and 2157\n",
      "e and 2158\n",
      "r and 2159\n",
      ", and 2160\n",
      "  and 2161\n",
      "y and 2162\n",
      "o and 2163\n",
      "u and 2164\n",
      "r and 2165\n",
      "  and 2166\n",
      "A and 2167\n",
      "c and 2168\n",
      "c and 2169\n",
      "o and 2170\n",
      "u and 2171\n",
      "n and 2172\n",
      "t and 2173\n",
      "  and 2174\n",
      "X and 2175\n",
      "X and 2176\n",
      "5 and 2177\n",
      "6 and 2178\n",
      "0 and 2179\n",
      "5 and 2180\n",
      "  and 2181\n",
      "h and 2182\n",
      "a and 2183\n",
      "s and 2184\n",
      "  and 2185\n",
      "b and 2186\n",
      "e and 2187\n",
      "e and 2188\n",
      "n and 2189\n",
      "  and 2190\n",
      "c and 2191\n",
      "r and 2192\n",
      "e and 2193\n",
      "d and 2194\n",
      "i and 2195\n",
      "t and 2196\n",
      "e and 2197\n",
      "d and 2198\n",
      "  and 2199\n",
      "w and 2200\n",
      "i and 2201\n",
      "t and 2202\n",
      "h and 2203\n",
      "  and 2204\n",
      "I and 2205\n",
      "N and 2206\n",
      "R and 2207\n",
      "  and 2208\n",
      "5 and 2209\n",
      ", and 2210\n",
      "5 and 2211\n",
      "2 and 2212\n",
      "1 and 2213\n",
      ". and 2214\n",
      "0 and 2215\n",
      "0 and 2216\n",
      "  and 2217\n",
      "o and 2218\n",
      "n and 2219\n",
      "  and 2220\n",
      "2 and 2221\n",
      "0 and 2222\n",
      "- and 2223\n",
      "N and 2224\n",
      "o and 2225\n",
      "v and 2226\n",
      "- and 2227\n",
      "1 and 2228\n",
      "8 and 2229\n",
      ". and 2230\n",
      "  and 2231\n",
      "I and 2232\n",
      "n and 2233\n",
      "f and 2234\n",
      "o and 2235\n",
      ": and 2236\n",
      "  and 2237\n",
      "N and 2238\n",
      "E and 2239\n",
      "F and 2240\n",
      "T and 2241\n",
      "- and 2242\n",
      "A and 2243\n",
      "X and 2244\n",
      "I and 2245\n",
      "C and 2246\n",
      "1 and 2247\n",
      "8 and 2248\n",
      "3 and 2249\n",
      "2 and 2250\n",
      "4 and 2251\n",
      "7 and 2252\n",
      "2 and 2253\n",
      "7 and 2254\n",
      "5 and 2255\n",
      "0 and 2256\n",
      "9 and 2257\n",
      "7 and 2258\n",
      "- and 2259\n",
      "T and 2260\n",
      "H and 2261\n",
      "O and 2262\n",
      "U and 2263\n",
      "G and 2264\n",
      "H and 2265\n",
      ". and 2266\n",
      "  and 2267\n",
      "T and 2268\n",
      "h and 2269\n",
      "e and 2270\n",
      "  and 2271\n",
      "A and 2272\n",
      "v and 2273\n",
      "a and 2274\n",
      "i and 2275\n",
      "l and 2276\n",
      "a and 2277\n",
      "b and 2278\n",
      "l and 2279\n",
      "e and 2280\n",
      "  and 2281\n",
      "B and 2282\n",
      "a and 2283\n",
      "l and 2284\n",
      "a and 2285\n",
      "n and 2286\n",
      "c and 2287\n",
      "e and 2288\n",
      "  and 2289\n",
      "i and 2290\n",
      "s and 2291\n",
      "  and 2292\n",
      "I and 2293\n",
      "N and 2294\n",
      "R and 2295\n",
      "  and 2296\n",
      "1 and 2297\n",
      "3 and 2298\n",
      ", and 2299\n",
      "5 and 2300\n",
      "5 and 2301\n",
      "3 and 2302\n",
      ". and 2303\n",
      "7 and 2304\n",
      "1 and 2305\n",
      ". and 2306\n",
      "R and 2307\n",
      "s and 2308\n",
      ". and 2309\n",
      "1 and 2310\n",
      "0 and 2311\n",
      "0 and 2312\n",
      "5 and 2313\n",
      "0 and 2314\n",
      "  and 2315\n",
      "i and 2316\n",
      "s and 2317\n",
      "  and 2318\n",
      "D and 2319\n",
      "e and 2320\n",
      "b and 2321\n",
      "i and 2322\n",
      "t and 2323\n",
      "e and 2324\n",
      "d and 2325\n",
      "  and 2326\n",
      "t and 2327\n",
      "o and 2328\n",
      "  and 2329\n",
      "A and 2330\n",
      "/ and 2331\n",
      "c and 2332\n",
      "  and 2333\n",
      ". and 2334\n",
      ". and 2335\n",
      ". and 2336\n",
      "4 and 2337\n",
      "9 and 2338\n",
      "7 and 2339\n",
      "1 and 2340\n",
      "  and 2341\n",
      "o and 2342\n",
      "n and 2343\n",
      "  and 2344\n",
      "0 and 2345\n",
      "1 and 2346\n",
      "- and 2347\n",
      "1 and 2348\n",
      "2 and 2349\n",
      "- and 2350\n",
      "1 and 2351\n",
      "8 and 2352\n",
      "  and 2353\n",
      "1 and 2354\n",
      "6 and 2355\n",
      ": and 2356\n",
      "0 and 2357\n",
      "4 and 2358\n",
      ": and 2359\n",
      "3 and 2360\n",
      "1 and 2361\n",
      "  and 2362\n",
      "( and 2363\n",
      "A and 2364\n",
      "v and 2365\n",
      "l and 2366\n",
      "b and 2367\n",
      "l and 2368\n",
      "  and 2369\n",
      "B and 2370\n",
      "a and 2371\n",
      "l and 2372\n",
      "  and 2373\n",
      "R and 2374\n",
      "s and 2375\n",
      ". and 2376\n",
      "2 and 2377\n",
      "0 and 2378\n",
      "6 and 2379\n",
      "1 and 2380\n",
      "5 and 2381\n",
      ". and 2382\n",
      "5 and 2383\n",
      "6 and 2384\n",
      ") and 2385\n",
      ". and 2386\n",
      "  and 2387\n",
      "S and 2388\n",
      "t and 2389\n",
      "a and 2390\n",
      "y and 2391\n",
      "  and 2392\n",
      "u and 2393\n",
      "p and 2394\n",
      "d and 2395\n",
      "a and 2396\n",
      "t and 2397\n",
      "e and 2398\n",
      "d and 2399\n",
      "  and 2400\n",
      "w and 2401\n",
      "i and 2402\n",
      "t and 2403\n",
      "h and 2404\n",
      "  and 2405\n",
      "y and 2406\n",
      "o and 2407\n",
      "u and 2408\n",
      "r and 2409\n",
      "  and 2410\n",
      "t and 2411\n",
      "x and 2412\n",
      "n and 2413\n",
      "s and 2414\n",
      ". and 2415\n",
      "  and 2416\n",
      "G and 2417\n",
      "e and 2418\n",
      "t and 2419\n",
      "  and 2420\n",
      "M and 2421\n",
      "o and 2422\n",
      "b and 2423\n",
      "i and 2424\n",
      "l and 2425\n",
      "e and 2426\n",
      "  and 2427\n",
      "B and 2428\n",
      "a and 2429\n",
      "n and 2430\n",
      "k and 2431\n",
      "i and 2432\n",
      "n and 2433\n",
      "g and 2434\n",
      "  and 2435\n",
      "a and 2436\n",
      "p and 2437\n",
      "p and 2438\n",
      "  and 2439\n",
      "h and 2440\n",
      "t and 2441\n",
      "t and 2442\n",
      "p and 2443\n",
      ": and 2444\n",
      "/ and 2445\n",
      "/ and 2446\n",
      "b and 2447\n",
      "i and 2448\n",
      "t and 2449\n",
      ". and 2450\n",
      "l and 2451\n",
      "y and 2452\n",
      "/ and 2453\n",
      "m and 2454\n",
      "c and 2455\n",
      "o and 2456\n",
      "n and 2457\n",
      "n and 2458\n",
      "e and 2459\n",
      "c and 2460\n",
      "t and 2461\n",
      "2 and 2462\n",
      "A and 2463\n",
      "n and 2464\n",
      "  and 2465\n",
      "A and 2466\n",
      "m and 2467\n",
      "o and 2468\n",
      "u and 2469\n",
      "n and 2470\n",
      "t and 2471\n",
      "  and 2472\n",
      "o and 2473\n",
      "f and 2474\n",
      "  and 2475\n",
      "1 and 2476\n",
      "0 and 2477\n",
      "0 and 2478\n",
      "0 and 2479\n",
      "0 and 2480\n",
      "  and 2481\n",
      "I and 2482\n",
      "N and 2483\n",
      "R and 2484\n",
      "  and 2485\n",
      "h and 2486\n",
      "a and 2487\n",
      "s and 2488\n",
      "  and 2489\n",
      "b and 2490\n",
      "e and 2491\n",
      "e and 2492\n",
      "n and 2493\n",
      "  and 2494\n",
      "c and 2495\n",
      "r and 2496\n",
      "e and 2497\n",
      "d and 2498\n",
      "i and 2499\n",
      "t and 2500\n",
      "e and 2501\n",
      "d and 2502\n",
      "  and 2503\n",
      "t and 2504\n",
      "o and 2505\n",
      "  and 2506\n",
      "A and 2507\n",
      "/ and 2508\n",
      "c and 2509\n",
      "  and 2510\n",
      "n and 2511\n",
      "o and 2512\n",
      "  and 2513\n",
      "X and 2514\n",
      "X and 2515\n",
      "X and 2516\n",
      "X and 2517\n",
      "X and 2518\n",
      "X and 2519\n",
      "X and 2520\n",
      "1 and 2521\n",
      "0 and 2522\n",
      "3 and 2523\n",
      "0 and 2524\n",
      "6 and 2525\n",
      "9 and 2526\n",
      "1 and 2527\n",
      "  and 2528\n",
      "b and 2529\n",
      "y and 2530\n",
      "  and 2531\n",
      "E and 2532\n",
      "F and 2533\n",
      "T and 2534\n",
      "  and 2535\n",
      "/ and 2536\n",
      "  and 2537\n",
      "A and 2538\n",
      "T and 2539\n",
      "M and 2540\n",
      "  and 2541\n",
      "C and 2542\n",
      "a and 2543\n",
      "r and 2544\n",
      "d and 2545\n",
      "  and 2546\n",
      "t and 2547\n",
      "r and 2548\n",
      "a and 2549\n",
      "n and 2550\n",
      "s and 2551\n",
      "a and 2552\n",
      "c and 2553\n",
      "t and 2554\n",
      "i and 2555\n",
      "o and 2556\n",
      "n and 2557\n",
      ". and 2558\n",
      "  and 2559\n",
      "o and 2560\n",
      "n and 2561\n",
      "  and 2562\n",
      "0 and 2563\n",
      "7 and 2564\n",
      "- and 2565\n",
      "J and 2566\n",
      "A and 2567\n",
      "N and 2568\n",
      "- and 2569\n",
      "1 and 2570\n",
      "9 and 2571\n",
      "  and 2572\n",
      "1 and 2573\n",
      "5 and 2574\n",
      ": and 2575\n",
      "1 and 2576\n",
      "6 and 2577\n",
      ": and 2578\n",
      "1 and 2579\n",
      "9 and 2580\n",
      ". and 2581\n",
      "  and 2582\n",
      "N and 2583\n",
      "o and 2584\n",
      "w and 2585\n",
      "  and 2586\n",
      "C and 2587\n",
      "l and 2588\n",
      "e and 2589\n",
      "a and 2590\n",
      "r and 2591\n",
      "  and 2592\n",
      "b and 2593\n",
      "a and 2594\n",
      "l and 2595\n",
      "a and 2596\n",
      "n and 2597\n",
      "c and 2598\n",
      "e and 2599\n",
      "  and 2600\n",
      "i and 2601\n",
      "s and 2602\n",
      "  and 2603\n",
      "C and 2604\n",
      "r and 2605\n",
      "e and 2606\n",
      "d and 2607\n",
      "i and 2608\n",
      "t and 2609\n",
      "  and 2610\n",
      "I and 2611\n",
      "N and 2612\n",
      "R and 2613\n",
      "  and 2614\n",
      "1 and 2615\n",
      "2 and 2616\n",
      "9 and 2617\n",
      "5 and 2618\n",
      "8 and 2619\n",
      ". and 2620\n",
      "9 and 2621\n",
      "4 and 2622\n",
      "F and 2623\n",
      "u and 2624\n",
      "n and 2625\n",
      "d and 2626\n",
      "  and 2627\n",
      "T and 2628\n",
      "r and 2629\n",
      "a and 2630\n",
      "n and 2631\n",
      "s and 2632\n",
      "f and 2633\n",
      "e and 2634\n",
      "r and 2635\n",
      "  and 2636\n",
      "t and 2637\n",
      "o and 2638\n",
      "  and 2639\n",
      "X and 2640\n",
      "X and 2641\n",
      "X and 2642\n",
      "X and 2643\n",
      "X and 2644\n",
      "X and 2645\n",
      "7 and 2646\n",
      "3 and 2647\n",
      "8 and 2648\n",
      "6 and 2649\n",
      "  and 2650\n",
      "- and 2651\n",
      "  and 2652\n",
      "s and 2653\n",
      "u and 2654\n",
      "c and 2655\n",
      "c and 2656\n",
      "e and 2657\n",
      "s and 2658\n",
      "s and 2659\n",
      "f and 2660\n",
      "u and 2661\n",
      "l and 2662\n",
      ". and 2663\n",
      "  and 2664\n",
      "R and 2665\n",
      "s and 2666\n",
      ". and 2667\n",
      "2 and 2668\n",
      ", and 2669\n",
      "0 and 2670\n",
      "0 and 2671\n",
      "0 and 2672\n",
      ". and 2673\n",
      "0 and 2674\n",
      "0 and 2675\n",
      "  and 2676\n",
      "d and 2677\n",
      "e and 2678\n",
      "b and 2679\n",
      "i and 2680\n",
      "t and 2681\n",
      "e and 2682\n",
      "d and 2683\n",
      "  and 2684\n",
      "f and 2685\n",
      "r and 2686\n",
      "o and 2687\n",
      "m and 2688\n",
      "  and 2689\n",
      "X and 2690\n",
      "X and 2691\n",
      "X and 2692\n",
      "X and 2693\n",
      "X and 2694\n",
      "X and 2695\n",
      "4 and 2696\n",
      "9 and 2697\n",
      "7 and 2698\n",
      "1 and 2699\n",
      ", and 2700\n",
      "T and 2701\n",
      "r and 2702\n",
      "a and 2703\n",
      "n and 2704\n",
      "s and 2705\n",
      "a and 2706\n",
      "c and 2707\n",
      "t and 2708\n",
      "i and 2709\n",
      "o and 2710\n",
      "n and 2711\n",
      "  and 2712\n",
      "I and 2713\n",
      "D and 2714\n",
      ": and 2715\n",
      "9 and 2716\n",
      "0 and 2717\n",
      "0 and 2718\n",
      "3 and 2719\n",
      "1 and 2720\n",
      "5 and 2721\n",
      "0 and 2722\n",
      "2 and 2723\n",
      "5 and 2724\n",
      "7 and 2725\n",
      "3 and 2726\n",
      "7 and 2727\n",
      ". and 2728\n",
      "  and 2729\n",
      "D and 2730\n",
      "a and 2731\n",
      "t and 2732\n",
      "e and 2733\n",
      "d and 2734\n",
      "  and 2735\n",
      "o and 2736\n",
      "n and 2737\n",
      "  and 2738\n",
      "0 and 2739\n",
      "3 and 2740\n",
      "- and 2741\n",
      "0 and 2742\n",
      "1 and 2743\n",
      "- and 2744\n",
      "2 and 2745\n",
      "0 and 2746\n",
      "1 and 2747\n",
      "9 and 2748\n",
      "A and 2749\n",
      "n and 2750\n",
      "  and 2751\n",
      "a and 2752\n",
      "m and 2753\n",
      "o and 2754\n",
      "u and 2755\n",
      "n and 2756\n",
      "t and 2757\n",
      "  and 2758\n",
      "o and 2759\n",
      "f and 2760\n",
      "  and 2761\n",
      "1 and 2762\n",
      "0 and 2763\n",
      "8 and 2764\n",
      "1 and 2765\n",
      "  and 2766\n",
      "I and 2767\n",
      "N and 2768\n",
      "R and 2769\n",
      "  and 2770\n",
      "h and 2771\n",
      "a and 2772\n",
      "s and 2773\n",
      "  and 2774\n",
      "b and 2775\n",
      "e and 2776\n",
      "e and 2777\n",
      "n and 2778\n",
      "  and 2779\n",
      "d and 2780\n",
      "e and 2781\n",
      "b and 2782\n",
      "i and 2783\n",
      "t and 2784\n",
      "e and 2785\n",
      "d and 2786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  and 2787\n",
      "t and 2788\n",
      "o and 2789\n",
      "  and 2790\n",
      "A and 2791\n",
      "/ and 2792\n",
      "c and 2793\n",
      "  and 2794\n",
      "n and 2795\n",
      "o and 2796\n",
      "  and 2797\n",
      "X and 2798\n",
      "X and 2799\n",
      "X and 2800\n",
      "X and 2801\n",
      "X and 2802\n",
      "X and 2803\n",
      "X and 2804\n",
      "1 and 2805\n",
      "0 and 2806\n",
      "3 and 2807\n",
      "0 and 2808\n",
      "6 and 2809\n",
      "9 and 2810\n",
      "1 and 2811\n",
      "  and 2812\n",
      "b and 2813\n",
      "y and 2814\n",
      "  and 2815\n",
      "F and 2816\n",
      "u and 2817\n",
      "n and 2818\n",
      "d and 2819\n",
      "  and 2820\n",
      "T and 2821\n",
      "r and 2822\n",
      "a and 2823\n",
      "n and 2824\n",
      "s and 2825\n",
      "f and 2826\n",
      "e and 2827\n",
      "r and 2828\n",
      "  and 2829\n",
      "o and 2830\n",
      "n and 2831\n",
      "  and 2832\n",
      "0 and 2833\n",
      "7 and 2834\n",
      "- and 2835\n",
      "D and 2836\n",
      "E and 2837\n",
      "C and 2838\n",
      "- and 2839\n",
      "1 and 2840\n",
      "8 and 2841\n",
      "  and 2842\n",
      "0 and 2843\n",
      "9 and 2844\n",
      ": and 2845\n",
      "0 and 2846\n",
      "3 and 2847\n",
      ": and 2848\n",
      "1 and 2849\n",
      "2 and 2850\n",
      ". and 2851\n",
      "  and 2852\n",
      "N and 2853\n",
      "o and 2854\n",
      "w and 2855\n",
      "  and 2856\n",
      "C and 2857\n",
      "l and 2858\n",
      "e and 2859\n",
      "a and 2860\n",
      "r and 2861\n",
      "  and 2862\n",
      "b and 2863\n",
      "a and 2864\n",
      "l and 2865\n",
      "a and 2866\n",
      "n and 2867\n",
      "c and 2868\n",
      "e and 2869\n",
      "  and 2870\n",
      "i and 2871\n",
      "s and 2872\n",
      "  and 2873\n",
      "C and 2874\n",
      "r and 2875\n",
      "e and 2876\n",
      "d and 2877\n",
      "i and 2878\n",
      "t and 2879\n",
      "  and 2880\n",
      "I and 2881\n",
      "N and 2882\n",
      "R and 2883\n",
      "  and 2884\n",
      "9 and 2885\n",
      "4 and 2886\n",
      "5 and 2887\n",
      "4 and 2888\n",
      ". and 2889\n",
      "9 and 2890\n",
      "4 and 2891\n"
     ]
    }
   ],
   "source": [
    " for jus in range(len(text)):\n",
    "    print(f\"{text[jus]} and {jus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E151] Trying to call nlp.update without required annotation types. Expected top-level keys: ('words', 'tags', 'heads', 'deps', 'entities', 'cats', 'links'). Got: ['e', 'n', 't', 'i', 't', 'i', 'e', 's'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-a15e4079b29c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Please do note here that model is overfit to show that it can learn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;31m# nlp.entity.update(d, g)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Losses\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;31m# Allow dict of args to GoldParse, instead of GoldParse objects.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_docs_and_golds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m_format_docs_and_golds\u001b[1;34m(self, docs, golds)\u001b[0m\n\u001b[0;32m    479\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0munexpected\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m                     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE151\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munexp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munexpected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m                 \u001b[0mgold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGoldParse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mgold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[0mdoc_objs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E151] Trying to call nlp.update without required annotation types. Expected top-level keys: ('words', 'tags', 'heads', 'deps', 'entities', 'cats', 'links'). Got: ['e', 'n', 't', 'i', 't', 'i', 'e', 's']."
     ]
    }
   ],
   "source": [
    "with nlp.disable_pipes(*other_pipes):  # only train ner\n",
    "    # optimizer = nlp.begin_training()\n",
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp.resume_training()\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        nlp.update(X, Y,  sgd=optimizer, drop=0.0, losses=losses) # Please do note here that model is overfit to show that it can learn\n",
    "        # nlp.entity.update(d, g)\n",
    "        print(\"Losses\", losses)\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Thrun PERSON\n",
      "Google ORG\n",
      "2007 DATE\n",
      "American NORP\n",
      "Thrun PERSON\n",
      "Recode ORG\n",
      "earlier this week DATED\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously. “I can tell you very senior CEOs of major \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " car companies would shake my hand and turn away because I wasn’t worth talking to,” said \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", in an interview with \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Recode\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    earlier this week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATED</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\") # or displacy.serve(doc, style=\"ent\") if not from jupyter notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc # https://spacy.io/api/doc\n",
    "\n",
    "import pandas as pd\n",
    "dpath = 'ner-token-per-line.biluo' # It not necessarily \n",
    "df = pd.read_csv(dpath, sep=',')\n",
    "words  = df.word.values\n",
    "ents = df.label.values\n",
    "text = ' '.join(words)\n",
    "\n",
    "spaces = [True]*len(words)\n",
    "spaces[-1] = False # so remove space in last\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces) # Custom Doc\n",
    "g = GoldParse(doc, entities=ents)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
